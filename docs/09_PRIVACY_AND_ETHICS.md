# 09 — プライバシー・法的・倫理的設計

## 1. プライバシーアーキテクチャ

### 1.1 ローカルファースト原則

VoiceReachは最も機密性の高い生体データ・個人データをローカルに保持し、クラウドには抽象化・匿名化されたデータのみを送信する。

```
┌────────────────────────────────────────────────┐
│                 患者端末（ローカル）              │
│                                                │
│  [永久ローカル保持 — 外部送信禁止]               │
│   ├ カメラ映像の生データ                        │
│   ├ 顔画像・顔特徴量                            │
│   ├ 視線追跡の生時系列データ                    │
│   ├ 表情・感情検出の生データ                    │
│   ├ 音声録音の生データ                          │
│   ├ 指センサーの生データ                        │
│   └ パーソナルベースラインモデル                 │
│                                                │
│  [ローカル保持 — 暗号化バックアップ可]           │
│   ├ PVP（Personal Voice Profile）               │
│   ├ 会話ログ                                    │
│   ├ 音声クローンモデル                          │
│   └ 登録済み顔データベース                      │
│                                                │
└───────────────────┬────────────────────────────┘
                    │ HTTPS（TLS 1.3）
                    │ 送信データ:
                    │  - PVP（構造化テキスト、~2000トークン）
                    │  - コンテキストフレーム（テキスト化済み）
                    │  - 会話履歴（直近10ターンのテキスト）
                    ↓
┌────────────────────────────────────────────────┐
│                 クラウドLLM API                   │
│  - ステートレス推論（データ保持なし）             │
│  - リクエストごとに破棄                          │
│  - ログに個人識別情報を記録しない                │
└────────────────────────────────────────────────┘
```

### 1.2 データ分類と保護レベル

| 分類 | データ例 | 保存場所 | 暗号化 | アクセス権 |
|---|---|---|---|---|
| 最高機密 | 顔映像、生体生データ | ローカルのみ | AES-256 | 患者本人のみ |
| 高機密 | PVP、会話ログ、音声 | ローカル+暗号化バックアップ | AES-256 | 患者+指定家族 |
| 中機密 | 状態サマリ、レポート | ローカル+介護者共有 | TLS転送時 | 介護チーム |
| 低機密 | システム設定、UIプリファレンス | ローカル+クラウド同期 | TLS転送時 | 患者+管理者 |

### 1.3 オンデバイス処理の最大化

PVP抽出パイプラインもオンデバイスLLM（Llama系、Phi系）で実行可能にする。

```
オンデバイス処理可能:
  ✅ 視線推定（MediaPipe + 軽量CNN）
  ✅ 表情追跡（MediaPipe Face Mesh）
  ✅ まばたき検出
  ✅ rPPG心拍推定
  ✅ 指入力処理
  ✅ PVP抽出（オンデバイスLLM）
  ✅ 候補生成（品質低下あり、オンデバイスLLM）
  ✅ 音声合成（ローカルモデル）

クラウド必須:
  ☁️ 高品質候補生成（大型LLM）
  ☁️ VLMによる高度なシーン認識
  ☁️ 高精度音声認識（大型ASRモデル）
```

---

## 2. 同意とデータ制御

### 2.1 インフォームドコンセント

```
同意が必要な項目:
  1. カメラによる常時顔撮影
  2. マイクによる常時音声モニタリング
  3. 過去のメール/SNS/音声からのPVP抽出
  4. 顔認識のための家族・介護者の顔登録
  5. クラウドLLMへのコンテキスト送信
  6. 介護者へのパッシブ検出情報の共有
  7. 音声クローンの作成と使用
  8. 医師向けレポートの自動生成

同意の取得方法:
  - 初期セットアップ時に一括ではなく、項目別に同意
  - いつでも撤回可能（設定画面から）
  - 意思決定能力がある段階で取得
  - 視線入力での同意操作も可能にする
```

### 2.2 データソース別の制御

患者は各データソースの使用範囲を細かく制御できる。

```
設定例:
  Gmail:
    ✅ 家族へのメール → PVPに使用
    ✅ 友人へのメール → PVPに使用
    ❌ 仕事のメール → PVPに使用しない
    ❌ 特定の相手のメール → 除外

  LINE:
    ✅ 妻とのトーク → PVPに使用
    ✅ 家族グループ → PVPに使用
    ❌ 特定のトークルーム → 除外

  出力制御:
    ✅ 家族への発話 → 全PVP適用
    ⚠️ 介護者への発話 → 丁寧スタイルのみ
    ❌ 特定のトピック → 候補に含めない
```

### 2.3 データ削除権

```
患者（または法的代理人）はいつでも以下を要求できる:
  - 特定のデータソースの削除
  - PVP全体のリセット
  - 会話ログの削除（全部 or 期間指定）
  - 音声録音の削除
  - 顔登録データの削除
  - アカウント全体の削除

削除は不可逆的に実行し、バックアップからも消去する。
クラウドLLMにはデータが残らない（ステートレス）ため、
クラウド側の削除は不要。
```

---

## 3. 法的論点

### 3.1 AI生成候補と「本人の意思」

VoiceReachの核心的な法的課題は、LLMが生成した候補を患者が選択した場合、それがどこまで「本人の意思表示」として認められるかである。

```
意思表示のスペクトラム:

完全に本人の意思                    完全にAIの意思
├────────────────────────────────────┤
│          │          │             │
自由文字   候補選択    候補修正     パッシブ
入力       (明示的)   なし選択    検出のみ
│          │          │             │
確実に     おそらく    グレー       困難
本人の     本人の     ゾーン
意思       意思
```

#### 候補選択が本人の意思と認められるための条件

```
1. 候補の多様性が確保されていること
   - 同じ方向の候補ばかりでは誘導になる
   - 意図軸分散がここでも重要

2. 拒否/修正の手段が常に利用可能であること
   - 「自分で入力する」オプションが常にある
   - 候補を全て拒否できる

3. 操作ログが残っていること
   - どの候補を見て、どれを選んだか
   - 何巡目で選んだか（即座に選んだ ≈ 強い意志）
   - 感情データとの整合性

4. システムの透明性
   - 候補がどう生成されたか説明可能
   - PVPの内容を本人/家族が確認・修正可能
```

### 3.2 法的に重要な場面での特別措置

```
延命治療の意思決定:
  - AI候補選択のみでは不十分
  - 自由文字入力での明示的な意思表示を求める
  - 複数回の確認（日を置いて再確認）
  - 医師・家族の立会い
  - 操作ログの詳細記録と保存
  - 可能なら公証人の関与

遺言:
  - 自筆証書遺言の代替としての法的有効性は未確立
  - 公正証書遺言の口授の代替として認められる可能性
  - 法務省・裁判所との事前確認が必要
  - 弁護士との連携体制を構築

財産管理の指示:
  - 候補選択による指示は補助的な参考情報として扱う
  - 法的拘束力のある指示は別途手続きが必要
```

### 3.3 認知機能低下への対応

ALS患者の約15〜20%にFTD（前頭側頭型認知症）の合併が報告されている。

```
リスク:
  - 認知機能低下により候補の意味を理解できなくなる
  - 不適切な候補を無意識に選択してしまう
  - 衝動的な選択が増える

対策:
  1. 認知機能スクリーニングの定期実施
     - 操作パターンの変化を自動検出
     - 選択の一貫性スコアを算出
     - 異常を検出したら家族・医師に通知

  2. セーフガードモード
     - 認知機能低下が疑われる場合に有効化
     - 重要な意思決定には家族の承認を要求
     - 候補の複雑度を下げる
     - 不可逆な操作（データ削除等）に追加確認

  3. 段階的な代理決定への移行
     - 本人の意思決定能力の評価を定期的に実施
     - 能力に応じた権限の段階的移行
     - 法的代理人の関与レベルを明確化
```

---

## 4. 「その人らしさ」のAI生成に関する倫理的境界

### 4.1 根本的な問い

```
Q: AIが「その人らしい」候補を生成し、患者がそれを選んだ場合、
   その発話は「本人の言葉」なのか「AIの言葉」なのか？

考察:
  - 健常者も自分の言葉を「自分で全て創造」しているわけではない
  - 言語は社会的に共有された道具であり、誰もが借用している
  - 候補を「選ぶ」行為自体が意思の表明である
  - PVPは本人の過去の表現から構築されたものである
  - ただし、AIのバイアスが混入する可能性は否定できない
```

### 4.2 設計上の倫理ガイドライン

```
1. 透明性の確保
   - 対話相手が「AIシステムを通じた発話である」ことを認識できる状態を維持
   - ただし、毎回明示する必要はない（初回説明で十分）

2. 操作防止
   - 候補生成にシステム提供者の意図を混入させない
   - 広告や特定の思想の誘導に使わない
   - PVPにないパターンを意図的に挿入しない

3. 尊厳の保護
   - 患者を「AIの入出力装置」として扱わない
   - 患者が候補に依存しすぎないよう、自由入力を常に提供
   - 「その人らしさ」の定義権は患者本人にある

4. 進化の余地
   - 患者の価値観や好みは変化しうる
   - PVPを「固定されたペルソナ」としてではなく
     「進化する参照点」として扱う
   - 患者が明示的に「こう変えたい」と言ったら反映する
```

---

## 5. 第三者のプライバシー

### 5.1 対話相手のデータ

```
対話相手（介護者、家族、訪問者）の:
  - 顔データ: ローカルのみ保持、本人の同意で登録
  - 発話テキスト: コンテキストとして一時的に使用、長期保存は選択制
  - 映像: 処理後即破棄、保存しない

対話相手の権利:
  - 顔登録の拒否権
  - 自分の発話ログの閲覧権
  - 自分の発話ログの削除権
  - 録音の停止要求権
```

### 5.2 PVP構築時の第三者データ

```
メール/LINE等から抽出する際:
  - 相手の発言内容はPVPに含めない（患者の表現パターンのみ抽出）
  - 相手の名前はPVP内で使用（対人スタイルの切替に必要）
  - 相手が希望すれば、その人とのやりとりをPVP構築から除外可能
```
