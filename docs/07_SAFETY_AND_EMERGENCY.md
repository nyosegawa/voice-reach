# 07 — 緊急時通信・オフライン耐性・エラーリカバリ

## 1. 緊急時通信設計

### 1.1 緊急度レベルの定義

| レベル | 状況例 | 必要応答時間 | トリガー方法 |
|---|---|---|---|
| 致命的 | 呼吸困難、窒息 | 即座 | パッシブ検出 + 自動通報 |
| 高 | 激しい痛み、吸引必要 | 10秒以内 | トリプルタップ or 緊急候補選択 |
| 中 | トイレ、体勢変更 | 1分以内 | 通常の候補選択 |
| 低 | 寒い/暑い、テレビ操作 | 数分以内 | 通常の候補選択 |

### 1.2 緊急コールの発動方法とIALフォールバック連携

VoiceReachのInput Abstraction Layer（IAL、設計書01 Section 3.3参照）と連携し、利用可能な入力チャネルに応じて緊急コールの発動方法を自動的に切り替える。

```
方法1: トリプルタップ（指が動く場合 — Stage 1-2）
  → 即座に緊急画面を表示
  → 緊急カテゴリを1タップで選択
  → 介護者全員に通知

方法2: まばたき3連打（指が動かない場合 — Stage 3-4）
  → 3秒以内に意図的な強いまばたきを3回検出
  → 誤検出防止: 確認画面を表示（2秒以内にまばたき1回で確定）
  → MediaPipe EAR（Eye Aspect Ratio）ベースで検出（レポートB7）
  → EAR閾値: 通常まばたき（EAR<0.2, 100-400ms）vs
    意図的まばたき（EAR<0.15, >400ms）で分離

方法3: パッシブ緊急検出（意識があるが操作できない場合）
  → バイタル異常（SpO2低下、心拍異常）
  → 表情の急激な変化（苦痛パターン検出）
  → 視線が固定したまま動かない（意識レベル低下の兆候）
  → 自動で介護者に通知（患者には確認を求めない）

方法4: 視線ジェスチャー緊急（まばたきも不安定な場合 — Stage 4）
  → 画面四隅への視線移動パターン（左上→右上→左上を3秒以内）
  → 確認画面を表示（視線で「はい」ゾーンを2秒滞留で確定）
```

**IALフォールバック自動切替ルール:**

| 入力状態 | 緊急トリガー | フォールバック先 |
|---|---|---|
| 指タップ正常 | トリプルタップ | — |
| 指タップ不能、まばたき正常 | まばたき3連打 | 自動切替（レポートB7 Tier 1） |
| 指タップ不能、まばたき不安定 | 視線ジェスチャー | 自動切替 |
| 指タップ・まばたき共に不能 | パッシブ検出のみ | バイタルモニタ必須 |
| EMGデバイス接続時 | EMG急速収縮3回 | IALアダプター経由 |

フォールバックの切替は、パーソナルベースラインの変化に基づき自動推奨される（設計書10 進行度適応参照）。緊急系のフォールバック変更は介護者の承認後に有効化される。

### 1.3 緊急画面

```
┌──────────────────────────────┐
│         ⚠️ 緊急通報          │
│                              │
│  ┌────────┐  ┌────────┐     │
│  │呼吸困難 │  │激しい痛み│    │
│  │        │  │        │     │
│  └────────┘  └────────┘     │
│  ┌────────┐  ┌────────┐     │
│  │吸引必要 │  │人を呼んで│    │
│  │        │  │        │     │
│  └────────┘  └────────┘     │
│                              │
│      [キャンセル（2連タップ）] │
└──────────────────────────────┘

選択 → 即座に:
  1. 介護者全員にプッシュ通知（音+バイブ）
  2. スマートスピーカーがあればアラーム音
  3. 患者画面に「通報しました」と表示
  4. 介護者が確認するまでアラート継続
```

### 1.4 誤報対策

```
誤報軽減策:
  - トリプルタップの間隔を1秒以内に限定
  - まばたき3連打は「強いまばたき」のみカウント（通常のまばたきは除外）
    → EAR閾値による分離（精度目標: 98%以上、レポートB7参照）
  - パッシブ検出は30秒間の持続的異常で発動（瞬間的な変動では発動しない）
  - 緊急画面には常に[キャンセル]オプションを表示

誤報時の対応:
  - 介護者がアプリで「誤報」をマーク
  - 誤報パターンを学習し、閾値を自動調整
  - 誤報が頻発する場合、設定画面で感度を手動調整可能
```

### 1.5 検出精度の数値目標

| 指標 | 目標値 | 備考 |
|---|---|---|
| 緊急トリガー検出率（真陽性率） | 99.5%以上 | 命に関わるため最優先 |
| 誤報率（偽陽性率） | 1日1回未満 | 介護者の信頼維持のため |
| まばたき緊急トリガー精度 | 98%以上 | MediaPipe EARベース（レポートB7: Eyeblink8で98.03%達成） |
| パッシブ検出感度 | 95%以上 | 30秒持続異常条件 |
| パッシブ検出特異度 | 99%以上 | 誤通報の社会的コスト考慮 |
| 緊急通知到達時間 | 3秒以内 | トリガーから介護者端末への通知完了まで |
| まばたき: 意図的/自然の分離精度 | 97%以上 | 個人適応後（ベースライン学習100まばたき以上） |

---

## 2. VLMによる危険状況自動検出（将来版）

### 2.1 概要

外向きカメラのVLM分析パイプライン（設計書01 Layer 2、レポートB5参照）を拡張し、患者周辺の危険状況を自動検出する。本機能は将来版（Phase 2以降）で実装する。

### 2.2 検出対象と方法

```
VLM危険状況検出パイプライン:

Layer 1: OpenCV動体検出（常時、CPU ~5%）
  └→ 急激な変化検出 → Layer 2をトリガー

Layer 2: ローカルVLM分析（MiniCPM-V 4.0、レポートB5推奨）
  └→ 安全関連プロンプトでシーン分析:
     - 患者の体勢異常（ベッドからの転落兆候）
     - 医療機器の異常表示（点滴残量ゼロ等）
     - 危険な物体の接近（倒れそうな物、水漏れ等）
     - 患者が独りの時間の長期化
```

| 検出シナリオ | VLM判定基準 | アクション |
|---|---|---|
| ベッドからの体勢ずれ | 体の位置がベッド端に偏移 | 介護者に「中」レベル通知 |
| 点滴残量低下 | 医療機器ディスプレイのOCR | 介護者に「情報」レベル通知 |
| 長時間独居 | 在室者ゼロが30分以上継続 | 介護者に「低」レベル通知 |
| 室内環境異常 | 暗所、異常な照度変化 | 介護者に「情報」レベル通知 |

### 2.3 安全設計の原則

- VLMの検出結果は**補助的情報**として扱い、自動的な医療判断は行わない
- 全ての検出は介護者への通知に留め、患者への直接介入は行わない
- モデルの幻覚（存在しない危険の報告）対策として、複数フレームでの確認を必須とする
- 誤検出率の目標: 1日3回未満（将来版リリース前にベッドサイド環境での実証テストを実施）

### 2.4 数値目標（将来版）

| 指標 | 目標値 | 測定方法 |
|---|---|---|
| 危険状況検出感度 | 90%以上 | 模擬シナリオ100件での評価 |
| 誤検出率（偽陽性） | 1日3回未満 | 実環境での7日間連続運用 |
| 検出→通知レイテンシ | 5秒以内 | 動体検出→VLM分析→通知送信 |
| VLM分析のGPU使用率 | 15%以下（断続使用） | 他パイプラインとの共存条件 |

---

## 3. オフライン耐性設計

### 3.1 オフライン時の機能レベル

| 機能 | オンライン | オフライン | 備考 |
|---|---|---|---|
| 緊急コール | 対応 | 対応（ローカル通知） | BLE/WiFi Direct で直接通知 |
| 定型文選択 | 対応 | 対応 | ローカルに定型文DB保持 |
| 視線追跡 | 対応 | 対応 | 完全ローカル処理 |
| 指入力 | 対応 | 対応 | 完全ローカル処理 |
| 文字入力 | 対応 | 対応 | 予測変換はオンデバイスLLM |
| AI候補生成（高品質） | 対応 | 縮退版で代替 | オンデバイスLLMで代替 |
| リスニングモード | 対応 | 精度低下で継続 | オンデバイスASRで代替 |
| PVP活用候補 | 対応 | 品質低下で継続 | オンデバイスLLM + PVP |
| 環境認識（VLM） | 対応 | ローカルVLMで継続 | MiniCPM-V 4.0で縮退動作 |
| 介護者通知 | 対応（プッシュ） | ローカルのみ | 同一WiFi内のみ |

### 3.2 オフラインアーキテクチャ: Qwen3-1.7Bによるローカル完結

オフライン時の候補生成品質を確保するため、Qwen3-1.7B（Q4_K_M量子化）をローカル推論のメインモデルとする（設計書01 Section 5.2、レポートB1参照）。

```
┌─────────────────────────────────────────────┐
│             患者端末（オフライン時）           │
│                                             │
│  [常時動作（ローカル）]                       │
│   ├ 視線推定エンジン                         │
│   ├ 指入力処理                               │
│   ├ まばたき検出（EAR + パターン分析）        │
│   ├ 感情検出（ベースラインベース）             │
│   └ UI表示                                   │
│                                             │
│  [縮退動作]                                  │
│   ├ Qwen3-1.7B (Q4_K_M) + vllm-mlx         │
│   │  → PVP込みの候補生成（日本語品質B+）     │
│   │  → 推論速度: ~320 tok/s (M4 Pro)        │
│   │  → メモリ: ~1.2GB                       │
│   │  → KVキャッシュ: PVP+指示プリフィクス    │
│   ├ Qwen3-0.6B (Q5_K_M)                     │
│   │  → 暫定候補の即時生成（~525 tok/s）      │
│   │  → メモリ: ~0.5GB                       │
│   ├ オンデバイスASR（Whisper tiny/small）     │
│   │  → リスニングモード（精度低下）           │
│   ├ ローカルVLM（MiniCPM-V 4.0）             │
│   │  → 環境認識の縮退動作（品質低下）         │
│   │  → メモリ: ~2.5GB                       │
│   └ ローカル定型文DB                         │
│       → 頻出フレーズ500件をプリロード         │
│                                             │
│  [無効化]                                    │
│   └ クラウドLLMによる高品質候補（Stage 3）    │
│                                             │
│  [ローカル通知]                              │
│   ├ BLE → 介護者スマートウォッチ             │
│   ├ WiFi Direct → 介護者スマートフォン       │
│   └ 音声アラート（スピーカー出力）            │
└─────────────────────────────────────────────┘
```

**オフラインでの性能仕様:**

| 指標 | オンライン時 | オフライン時 | 劣化度 |
|---|---|---|---|
| 候補生成品質 | A-（クラウドLLM） | B+（Qwen3-1.7B） | やや低下 |
| Stage 1候補表示レイテンシ | ~150ms | ~150ms | 変化なし |
| Stage 2候補表示レイテンシ | ~350ms | ~350ms | 変化なし |
| Stage 3候補表示レイテンシ | ~800ms（クラウド） | N/A（無効化） | Stage 2で完結 |
| VLM環境認識 | 高精度（クラウドフォールバック可） | 中精度（ローカルのみ） | やや低下 |
| 機能カバー率 | 100% | 70%以上 | 設計書01非機能要件準拠 |

### 3.3 データ同期

```
オフライン → オンライン復帰時:
  1. オフライン中の会話ログをクラウドに同期
  2. PVP更新データがあれば反映
  3. オンデバイスLLMの候補をクラウドLLMに切替
  4. 介護者への未送信通知を再送
```

---

## 4. エラーリカバリ設計

### 4.1 誤選択のリカバリ

```
問題: 意図しない候補を選択してしまった

対策1: 確定前プレビュー
  チラ見 + タップ
    → 候補がハイライト表示（0.8秒間）
    → この間にもう1タップで本確定
    → タップしなければ自動キャンセル

対策2: 直後キャンセル
  確定後2秒以内にダブルタップ → 取り消し
  音声合成が開始していた場合は即停止
  介護者画面に「訂正中」と表示

対策3: 訂正発話
  誤発話後に「違う、○○」と正しい候補を選択
  介護者画面に訂正履歴を表示

フロー:
  タップ → [0.8秒プレビュー] → タップで確定 → [2秒キャンセル猶予] → 発話
```

### 4.2 不随意運動によるミスタップ対策

```
対策1: 視線ゲーティング
  - 視線がUI上の候補ゾーンにない場合、タップを無視
  - 設定で ON/OFF 可能（視線追跡精度が低い場合はOFF）

対策2: 圧力波形フィルタ
  - 不随意運動は不規則で小さい振動パターン
  - 意図的タップは明確な立ち上がりと立ち下がり
  - 波形パターンで分類（個人適応あり）

対策3: タイムアウト
  - タップ後0.8秒以内に視線が候補から離れた場合、無効とする
```

### 4.3 システム障害時のフォールバック

IAL（Input Abstraction Layer）と連携した段階的フォールバック（設計書01 Section 3.3、レポートB7参照）。

```
障害レベル1: 視線追跡の精度低下
  → ゾーン数を自動削減（9→4→2）
  → 指入力のみのモードを提示

障害レベル2: カメラが使用不能
  → 指入力のみのモードに切替
  → 定型文リストをスクロール（タップ/ダブルタップで操作）

障害レベル3: 指センサーが使用不能
  → IALがまばたき入力モードに自動切替（レポートB7 Tier 1推奨）
  → まばたきパターン:
    シングル（長め）= 確定
    ダブル = キャンセル
    ロング（1秒以上閉眼）= メニュー展開
  → 視線+まばたきの組み合わせ入力にフォールバック
  → Dwell Click方式は最終手段として残すが非推奨
    （疲労問題のため、レポートA2参照）

障害レベル4: ネットワーク断絶
  → オフラインモードに自動切替（上記3.2参照）
  → Qwen3-1.7Bによるローカル完結で70%以上の機能を維持

障害レベル5: 電源断
  → UPS（無停電電源装置）推奨
  → バッテリー残量20%でアラート
  → 5%で自動的に緊急コールのみのモードに
```

**フォールバック切替の検出精度目標:**

| 障害検出 | 検出時間 | 精度目標 |
|---|---|---|
| 視線追跡精度低下 | 5秒以内 | 校正誤差が閾値超過で自動判定 |
| カメラ障害 | 1秒以内 | フレーム取得失敗で即検出 |
| 指センサー障害 | 3秒以内 | 信号途絶+ベースライン逸脱で判定 |
| ネットワーク断絶 | 5秒以内 | API応答タイムアウトで判定 |
| 電源低下 | 即時 | OS電源管理APIによる監視 |

---

## 5. 長文コミュニケーション設計

### 5.1 短文モード vs 長文モード

```
短文モード（デフォルト）:
  - 会話用。1〜2文の発話を生成
  - 候補選択UIで操作

長文モード:
  - 手紙、メール、医師への説明等
  - LLMに下書きを書かせ、患者が承認/修正するコラボレーション型
```

### 5.2 長文モードのフロー

```
1. 患者が長文モードを選択（メニューから）

2. 目的を指定
   [メール] [手紙] [医師への説明] [SNS投稿] [その他]

3. 相手を指定
   [花子] [田中先生] [太郎] [自由入力]

4. トピック/キーワードを入力（2ストローク方式 or 候補選択）
   例: "背中" "痛い" "3日前から"

5. LLMがPVPベースで下書きを生成
   "田中先生、お世話になっています。3日前から背中に
    痛みがあり、特に夜間に強くなります。
    体勢を変えても改善しません。次回の診察で
    ご相談させてください。よろしくお願いいたします。"

6. 患者が確認
   [OK] [部分修正] [書き直し]

7. 部分修正の場合:
   修正箇所をゾーン選択 → 修正候補を提示 → 選択
   例: "夜間に" → ["午後から", "食後に", "寝返り時に"]

8. 確定 → 送信 or 音声読み上げ
```

---

## 6. 複数人会話への対応

### 6.1 対話相手の指定

```
部屋に複数人いる場合:

方法1: 視線方向
  患者が見ている方向に誰がいるかを外部カメラで検出
  → その人向けのスタイルで候補生成

方法2: 明示的切替
  候補表示エリアの端に対話相手インジケーターを表示
  "花子" ← [切替] → "看護師A"

方法3: 「みんなに」モード
  全員向けの発話として処理。最もフォーマルなスタイルを適用。
```

### 6.2 グループ会話での短い相槌

複数人が会話している場面では、長い発言より短い相槌の方が自然。

```
グループ会話検出時の候補傾向:
  - 短い相槌を優先: "そうだね" "うん" "へぇ"
  - 笑い: "笑" "ははは"
  - 同意/驚き: "それはすごい" "ほんとに？"
  - 質問（短い）: "いつ？" "誰？" "なんで？"

通常時よりも候補の文を短くし、テンポよく返せるようにする。
```

---

## 7. 出典・参照

- レポートA2: AAC Communication Systems Research Report — Dwell-Click疲労問題、フォールバック要件
- レポートB1: LLM調査レポート — Qwen3-1.7Bローカル推論性能
- レポートB5: VLM調査レポート — Section 5.1 (ハイブリッド3層構成)、Section Q5 (プライバシー)、Section 5.5 (リスク)
- レポートB7: 最新入力デバイス調査レポート — Section RQ3 (まばたき検出、EAR精度98.03%)、Section RQ7 (フォールバック階層)、Section 6.1 (フォールバック優先順位)、Section 6.2 (IAL設計)
- 設計書01: システムアーキテクチャ詳細設計 — Section 3.3 (IAL)、Section 5.2 (三段ハイブリッド推論)、Section 9 (非機能要件: オフライン70%以上)
- 設計書10: 進行度適応設計 — パーソナルベースラインに基づくフォールバック推奨
- Soukupova & Cech (2016). "Real-Time Eye Blink Detection using Facial Landmarks." CVWW.
- Springer (2024). "Proposal for Eye Blink Detection Using MediaPipe, EAR and Peak Identification." — Eyeblink8データセットで98.03%精度
