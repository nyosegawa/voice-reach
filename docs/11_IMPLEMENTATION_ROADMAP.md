# 11 --- 実装ロードマップ・検証計画・KPI

## 1. 開発フェーズ概要

```
  Phase 0     Phase 0.5     Phase 1        Phase 2        Phase 3
 音声保存先行  モデル評価      MVP           拡張          最適化・普及
 + 環境構築   + ベンチマーク
├──────────┼──────────┼───────────┼───────────┼───────────┤
0ヶ月       2ヶ月      4ヶ月       10ヶ月      16ヶ月      24ヶ月
```

---

## 2. Phase 0: 音声保存先行 + 環境構築（0--2ヶ月）

プロダクト開発と並行して、タイムクリティカルな音声保存を先行開始する。同時に開発用ハードウェアの調達とソフトウェア環境を構築する。

### 2.1 録音プロトコル

```
録音環境のセットアップ:
  - 静音環境（30dB以下推奨）、外付けコンデンサマイク or スマートフォン
  - サンプリングレート: 44.1kHz以上、16bit以上、WAVフォーマット
  - 患者の顔から30-50cmの距離にマイクを設置

読み上げ文章セット:
  - 日本語音素網羅版テキスト（50音+促音+拗音+長音）
  - 自然会話トピックリスト（家族との思い出、趣味、日常の言い回し）
  - 感情バリエーション（喜怒哀楽のトーンで同一文を録音）

目標録音量:
  - CosyVoice 2/3 few-shot用: 最低5秒、推奨30秒-3分
  - GPT-SoVITS v4 ファインチューニング用: 30分-1時間
  - 安全マージン含め計2-3時間の音声データを確保

品質チェック:
  - 録音後にSN比を自動計測（SNR ≥ 25dB）
  - クリッピング・ノイズの自動検出
  - セッション管理と進捗表示
```

### 2.2 開発環境構築（Mac mini M4 Pro）

メインデバイスとして Mac mini M4 Pro (24GB) を調達し、開発・検証環境を構築する（レポートB6）。

| 項目 | 内容 |
|------|------|
| デバイス | Mac mini M4 Pro (24GB / 512GB SSD) |
| OS | macOS 15 Sequoia 以降 |
| 推論FW | vllm-mlx（OpenAI互換API、連続バッチング）+ MLX (mlx-lm) |
| Python | 3.11+、uv (パッケージマネージャ) |
| アプリFW | Electron + React（患者UI）、PWA（介護者UI） |
| CI/CD | GitHub Actions + ローカルテスト |

### 2.3 成果物

```
- 録音ガイドブック（PDF）+ 簡易録音アプリ（スマートフォン）
- 暗号化クラウドストレージ（録音データ保管）
- Mac mini M4 Pro 開発環境一式（MLX + vllm-mlx + MediaPipe動作確認済み）
- 医療機関連携の開始（協力医・言語聴覚士の確保）
```

### 2.4 ターゲット

- 診断後3ヶ月以内のALS患者 5名以上に録音パッケージを提供
- 構音障害進行前の音声データを確保
- 開発環境で全パイプライン（視線推定 + LLM + TTS + VLM）の基礎動作を確認

---

## 3. Phase 0.5: モデル評価・実機ベンチマーク（2--4ヶ月）

Phase 1のMVP開発に先立ち、選定した主要モデルの実機性能を検証する。ここでの計測値が以降のPhaseのKPI・アーキテクチャ判断の基礎となる。

### 3.1 評価対象モデル

| カテゴリ | モデル | 量子化 | 評価項目 |
|----------|--------|--------|----------|
| 視線推定 | MediaPipe Face Mesh + MobileOne s0 + L2CS-Net | FP16 | FPS、精度（角度誤差）、CPU/GPU使用率 |
| ローカルLLM (即座) | Qwen3-0.6B | Q5_K_M | tok/s、TTFT、日本語候補品質、メモリ使用量 |
| ローカルLLM (標準) | Qwen3-1.7B | Q4_K_M | tok/s、TTFT、日本語候補品質、メモリ使用量 |
| TTS | CosyVoice 2/3 | FP16/INT8 | 初回発声レイテンシ、MOS、話者類似度、メモリ使用量 |
| VLM | MiniCPM-V 4.0 (4.1B) | Q4_K_M | tok/s、シーン記述精度、メモリ使用量 |
| クラウドLLM | Gemini 2.5 Flash / Claude Haiku 4.5 | -- | TTFT、総レイテンシ、日本語品質、月額コスト実測 |

### 3.2 ベンチマーク手順

```
1. 単体ベンチマーク:
   各モデルを個別にロードし、以下を計測:
   - 推論速度（tok/s or FPS）
   - メモリ使用量（RSS）
   - GPU使用率（asitop/powermetrics）
   - レイテンシ分布（P50/P95/P99）

2. 全パイプライン同時実行ベンチマーク:
   全モデルを同時にロードし、同時実行時の性能劣化を計測:
   - 合計メモリ使用量（目標: ≤ 12GB / 24GB中）
   - ピークGPU使用率（目標: ≤ 60%）
   - 各タスクのレイテンシ劣化率

3. 長時間安定性テスト:
   24時間連続稼働でメモリリーク・温度推移・クラッシュ頻度を計測

4. TTS音声品質評価:
   - Phase 0で録音した実音声を用いてfew-shot/ファインチューニング
   - MOS評価（5段階、評価者5名以上）
   - 話者類似度スコア（SIM-o）
```

### 3.3 合否基準（Go/No-Go）

| 指標 | 合格基準 | 不合格時のアクション |
|------|----------|----------------------|
| 視線推定FPS | ≥ 25fps（同時実行時） | MobileOne s0 → MobileNetV3に変更 |
| 視線推定精度 | ≤ 2.5°（5点校正後） | 校正アルゴリズム改善 or IR補助LED追加 |
| Qwen3-1.7B tok/s | ≥ 250 tok/s（同時実行時） | Qwen3-0.6Bのみに変更し、Stage 2を廃止してクラウド直行 |
| CosyVoice 初回発声 | ≤ 500ms | ストリーミング再生の最適化、またはVOICEVOXへ変更 |
| TTS MOS | ≥ 4.0（本人の声クローン） | 録音品質改善 or GPT-SoVITS v4併用 |
| 全パイプラインメモリ | ≤ 14GB / 24GB | VLMを軽量化（Moondream 2B）or 断続実行に変更 |
| 24h安定性 | クラッシュ0回、メモリ増加 ≤ 500MB | メモリリーク箇所の特定・修正 |
| クラウドLLM総レイテンシ | ≤ 1.5s（Gemini 2.5 Flash） | リージョン変更、またはClaude Haiku 4.5に切替 |

### 3.4 成果物

```
- 実機ベンチマークレポート（全モデルの計測値・グラフ）
- Go/No-Go判定結果と、不合格項目への対応方針
- 最終技術スタック確定ドキュメント
- TTS音声サンプル（評価済みMOSスコア付き）
```

---

## 4. Phase 1: MVP（4--10ヶ月）

### 4.1 MVPスコープ

```
含む:
  - Webカメラ視線推定: MediaPipe Face Mesh + MobileOne s0 + L2CS-Net
    （ゾーンベース、4-9ゾーン、5点校正で ≤ 2.5°）
  - デュアルセンサ指入力: PZT圧電ディスク + FSR-402 + XIAO RP2040
    （シングルタップ / ダブルタップ / ロングプレス / トリプルタップ）
  - 三段ハイブリッドLLM推論:
    Stage 1: Qwen3-0.6B (Q5) → 暫定候補 ~150ms
    Stage 2: Qwen3-1.7B (Q4) → 改善候補 ~350ms
    Stage 3: Gemini 2.5 Flash → 高品質候補 ~800ms
    フォールバック: Claude Haiku 4.5 → GPT-4.1 nano
  - 定型文選択（カスタマイズ可能、ローカルDB）
  - 2ストローク文字入力（ゾーンベースひらがな）
  - 緊急コール（トリプルタップ → 介護者通知）
  - 基本的な介護者PWA（プッシュ通知 + 発話ログ）
  - 市販TTS音声（CosyVoice 2/3、本人の声ではないデフォルト話者）
  - vllm-mlxによるOpenAI互換APIサーバー（プロンプトキャッシュ対応）

含まない（Phase 2以降）:
  - PVP構築・活用
  - リスニングモード
  - 感情検出（パッシブ）
  - 外部環境認識（VLM）
  - 意図軸分散ナビゲーション
  - 本人の声での音声合成
  - オフラインモード（ネットワーク断時の自動切替）
  - 長文モード
```

### 4.2 技術タスク

```
[視線推定エンジン]
  - MediaPipe Face Mesh 468点ランドマーク統合（~5ms）
  - MobileOne s0 バックボーン + L2CS-Net dual loss 統合（~3ms）
  - 5点キャリブレーション機能
  - ゾーンマッピング + ヒステリシス（境界でのチャタリング防止）
  - Kalmanフィルタによるスムージング

[指入力ドライバ]
  - PZT圧電ディスク + FSR-402 → XIAO RP2040 → USB HID
  - 4層フィルタリング実装:
    Layer 1: ハードウェアRCフィルタ（160Hz LPF）
    Layer 2: 時間的デバウンス（30-200ms、ステージ別）
    Layer 3: 波形テンプレートマッチング（不随意運動除去）
    Layer 4: コンテキスト認識ゲーティング（視線位置連携）
  - 感度調整UI

[三段ハイブリッドLLM推論]
  - vllm-mlxサーバー起動（Qwen3-0.6B + Qwen3-1.7B同時ロード）
  - プロンプトキャッシュ設計（PVP+指示をプレフィックスキャッシュ、TTFT実質0ms）
  - Gemini 2.5 Flash API統合（プライマリクラウド）
  - Claude Haiku 4.5 API統合（セカンダリクラウド）
  - 候補4つの生成・表示・差し替えロジック
  - 2秒タイムアウト + フォールバック制御

[患者UI]
  - Electron + React フルスクリーンアプリ
  - フローティングバブルUI（候補4つ表示）
  - 文字入力画面（2ストロークひらがな）
  - 設定画面（キャリブレーション、感度調整）
  - 緊急画面（トリプルタップで起動）

[介護者アプリ]
  - PWA（スマートフォン向け）
  - プッシュ通知（緊急 / 通常）
  - 発話ログ表示
  - 基本的な状態表示

[インフラ]
  - vllm-mlxローカルAPIサーバー
  - WebSocket通信（患者端末 <-> 介護者端末）
  - 基本的なユーザー管理
```

### 4.3 指入力デバイスBOM（レポートA6）

| コンポーネント | 製品 | 価格 |
|--------------|------|------|
| MCU | Seeed XIAO RP2040 | $6 |
| 1次センサ | 27mm PZT圧電ディスク | $1 |
| 2次センサ | Interlink FSR-402 | $8 |
| 精密ADC | ADS1115（Stage 3用、初期はXIAO内蔵ADCで代替可） | $15 |
| その他（基板、ケーブル、筐体） | -- | ~$11 |
| **合計BOM** | | **~$41** |

### 4.4 ユーザーテスト

```
テスト参加者: ALS患者 3-5名（Stage 1-2）
テスト期間: 2週間
テスト環境: 自宅（訪問セットアップ）
計測項目:
  - セットアップ所要時間
  - キャリブレーション成功率
  - 定型文選択の速度と正確性
  - 文字入力の速度（文字/分）
  - 候補命中率（1巡目で選ばれた割合）
  - 1日の発話数
  - SUS（System Usability Scale）スコア
  - 患者・介護者の定性フィードバック
```

---

## 5. Phase 2: 拡張（10--16ヶ月）

### 5.1 機能追加

```
[PVPシステム]
  - データソースコネクタ（Gmail API, LINEエクスポート）
  - 抽出パイプライン（正規化 → サンプリング → パターン抽出）
  - PVP管理UI（確認・編集）
  - PVP活用の候補生成プロンプト（~2000トークン）

[意図軸分散ナビゲーション]
  - 7軸フレームワークの実装
  - 視線滞留フィードバック → 2巡目候補生成
  - 多巡ナビゲーションロジック
  - バリエーション展開（ロングプレス）

[リスニングモード]
  - 音声認識: ローカル Whisper small (MLX) + クラウド Gemini 2.5 Flash
  - 話者認識（顔 + 声の照合）
  - 相手の発話からの返答候補自動生成

[感情検出（4チャネル）]
  - Ch1: 瞳孔径変動（MediaPipe）
  - Ch2: rPPG心拍推定（open-rppg）
  - Ch3: 視線パターン時系列
  - Ch4: まばたきパターン
  - valence / arousal / confidence / frustration の出力
  - フラストレーション検出 + エスケープUI

[音声合成（本人の声）]
  - CosyVoice 2/3 によるfew-shotボイスクローン（Phase 0録音データ活用）
  - GPT-SoVITS v4 によるファインチューニング（高品質版）
  - トーン制御（相手別・感情別）via EmoKnobフレームワーク
  - 目標: MOS ≥ 4.0

[環境認識（VLM）]
  - MiniCPM-V 4.0 (4.1B, Q4) ローカルVLM（5-10秒間隔スナップショット）
  - OpenCV動体検出（常時、CPU ~5%）→ VLMトリガー
  - 人物認識（顔登録・自動切替）
  - シーン記述 → コンテキスト統合層へ
  - クラウドフォールバック: Gemini 2.5 Flash VLM（患者同意時のみ）

[介護者機能拡張]
  - YesNo質問モード
  - 引き継ぎサマリ自動生成
  - 医師向けレポート出力
  - 状態サマリ画面
```

### 5.2 ユーザーテスト（拡大）

```
テスト参加者: ALS患者 10-15名（Stage 1-3）
テスト期間: 1ヶ月
追加計測項目:
  - PVP活用時の候補命中率向上度
  - リスニングモードの使用頻度と有効性
  - 感情検出の精度（主観評価との相関）
  - 意図到達時間の改善
  - 介護者の負担感変化
  - TTS MOS評価（本人の声クローン）
```

---

## 6. Phase 3: 最適化・普及（16--24ヶ月）

### 6.1 機能追加・最適化

```
[オフライン耐性]
  - Qwen3-1.7B (Q4) + CosyVoice 2/3 + Whisper small のローカル完結
  - ローカル通知（BLE / WiFi Direct）
  - オフライン / オンライン自動切替（クラウドヘルスチェック30秒間隔）
  - オフライン時は三段推論の Stage 3 を無効化、Stage 1-2 で候補確定

[進行度適応]
  - Input Abstraction Layer（IAL）による入力デバイス透過切替
  - チャネル信頼性の自動評価と重み再配分
  - まばたき入力モード（EAR: Eye Aspect Ratio ベース）
  - Stage別パラメータ自動調整（ALSFRS-Rスケール連携）

[先読みプリフェッチ]
  - 各候補が選ばれなかった場合の2巡目候補をバックグラウンド生成
  - バッチAPI利用で50%コスト削減（レポートB2）
  - 次会話ターンの先行生成

[長文モード]
  - LLMコラボレーション型下書き生成
  - 部分修正UI
  - メール / 手紙送信連携

[夜間モード]
  - 低照度対応（IR対応Webカメラ推奨）
  - 近赤外LED補助（オプション）
  - 代替入力の優先度変更

[パフォーマンス最適化]
  - vllm-mlx連続バッチング最適化（MLX比21-87%高スループット、レポートB6）
  - メモリ使用量の継続削減
  - M5チップ対応テスト（TTFT 3x改善見込み、レポートB6）
```

### 6.2 普及活動

```
- 日本ALS協会（JALSA）との連携・ユーザー紹介
- 難病支援センターへの紹介
- 補装具費支給制度の対象認定に向けた申請（テクノエイド協会、レポートA2）
- 国際福祉機器展（H.C.R.）への出展
- 論文発表（HCI / Assistive Technology分野）
- オープンソース化の検討（コアコンポーネント）
```

---

## 7. KPI（重要業績評価指標）

### 7.1 主要KPI

| KPI | 定義 | Phase 1目標 | Phase 2目標 | Phase 3目標 |
|-----|------|-------------|-------------|-------------|
| 意図到達時間 | 言いたいことが伝わるまでの平均秒数 | 15秒 | 5秒 | 3秒 |
| 候補1巡目命中率 | 最初の4候補で選択された割合 | 30% | 55% | 65% |
| 1日の発話数 | 患者が1日に発話した回数 | 15回 | 30回 | 50回 |
| 眼球疲労スコア | 主観評価（1--10、低いほど良い） | 6 | 4 | 3 |
| 誤選択率 | 意図しない候補を確定した割合 | 10% | 5% | 3% |
| 介護者満足度 | NPS（Net Promoter Score） | 30 | 50 | 70 |
| 患者満足度 | カスタム満足度調査（1--5） | 3.0 | 3.8 | 4.2 |

### 7.2 技術KPI

| KPI | 定義 | 目標 |
|-----|------|------|
| **視線推定精度** | **5点校正後の角度誤差** | **≤ 2.5°** |
| **レイテンシ（Stage 1 候補）** | **Qwen3-0.6B トリガーから候補表示まで** | **≤ 150ms** |
| **レイテンシ（Stage 2 候補）** | **Qwen3-1.7B トリガーから候補表示まで** | **≤ 350ms** |
| **レイテンシ（Stage 3 候補）** | **Gemini 2.5 Flash トリガーから候補表示まで** | **≤ 800ms** |
| **エンドツーエンドレイテンシ** | **視線選択から最終候補確定まで** | **≤ 500ms（ローカル）** |
| カメラ処理FPS | 視線推定 + 表情追跡の処理速度 | ≥ 25fps |
| TTS初回発声レイテンシ | テキスト確定から音声出力開始まで | ≤ 500ms |
| **TTS音声自然性** | **MOS（Mean Opinion Score）** | **≥ 4.0** |
| オフライン動作率 | ネットワーク断時に動作する機能の割合 | ≥ 70% |
| PVP抽出精度 | 家族が「らしい」と評価した割合 | ≥ 80% |
| 感情検出精度 | valence方向の正答率（快/不快/中立の3分類） | ≥ 70% |
| 全パイプラインメモリ | LLM + VLM + TTS + 視線推定 + OS合計 | ≤ 12GB / 24GB |
| ピークGPU使用率 | 全パイプライン同時実行時 | ≤ 60% |

### 7.3 ビジネスKPI

| KPI | Phase 1 | Phase 2 | Phase 3 |
|-----|---------|---------|---------|
| ユーザー数（患者） | 5 | 30 | 100 |
| 利用継続率（3ヶ月） | 60% | 75% | 85% |
| 平均日次セッション時間 | 1時間 | 3時間 | 6時間以上 |
| 連携医療機関数 | 2 | 10 | 30 |
| 介護者アプリDAU | 5 | 50 | 200 |

---

## 8. コストモデル

### 8.1 ハードウェア初期費用（レポートB6）

| 構成 | 主要デバイス | 内容物 | 価格帯（税込） |
|------|-------------|--------|---------------|
| エントリー | Mac mini M4 (24GB) | 本体 + Webカメラ x2 + モニター + UPS | **~¥155K** |
| **推奨** | **Mac mini M4 Pro (24GB)** | **本体 + IR対応カメラ + 広角カメラ + モニター + UPS + スピーカー** | **~¥277K** |
| プレミアム | Mac mini M4 Max (48GB) | 上記 + 4K対応 + 大型UPS | ~¥400K+ |

**構成別性能（レポートB6）**:
- エントリー: LLM ~200 tok/s（Qwen3-1.7B Q4）、VLMは軽量モデル推奨
- 推奨: LLM ~320 tok/s、全パイプライン同時実行で余裕（メモリ~11GB/24GB）
- プレミアム: 将来拡張性最大、4B以上のLLMも実行可能

### 8.2 指入力デバイス費用（レポートA6）

| 部品 | 価格 |
|------|------|
| Seeed XIAO RP2040 | $6 |
| 27mm PZT圧電ディスク | $1 |
| Interlink FSR-402 | $8 |
| ADS1115 精密ADC | $15 |
| その他（基板・ケーブル・筐体） | ~$11 |
| **合計BOM** | **~$41（約¥6,200）** |

### 8.3 クラウドAPI月額費用（レポートB2）

| 使用パターン | Gemini 2.5 Flash (主) | Claude Haiku 4.5 (副) | 合計/月 |
|-------------|----------------------|----------------------|---------|
| 基本（50回/日） | ~$1.5 | ~$0.5 | **~$2.0** |
| 標準（75回/日） | ~$2.0 | ~$1.0 | **~$3.0** |
| 高頻度（100回/日） | ~$3.0 | ~$1.5 | **~$4.5** |
| 先読み込み（バッチAPI 50%OFF） | +$0.5-1.0 | +$0.5-1.0 | **+$1.0-2.0** |
| **想定月額レンジ** | | | **$5-8** |

前提: PVPキャッシュヒット率80%、Gemini 80-90% + Claude 10-20%の呼び出し配分。プロンプトキャッシュ適用（Anthropic/Google共に読み込み90%OFF）。

### 8.4 トータルコスト概算

| 項目 | 初年度 | 2年目以降/年 |
|------|--------|-------------|
| ハードウェア（推奨構成） | ~¥277,000 | ¥0（耐用年数5年） |
| 指入力デバイス | ~¥6,200 | ¥0 |
| モニター + 周辺機器 | ~¥30,000 | ¥0 |
| クラウドAPI（$5-8/月） | ~¥100,000 | ~¥100,000 |
| **合計** | **~¥413,200** | **~¥100,000** |

### 8.5 補装具費支給制度の活用（レポートA2）

日本の公費制度を活用することで、患者負担を大幅に軽減できる。

| 制度 | 内容 |
|------|------|
| 対象制度 | **補装具費支給制度**（重度障害者用意思伝達装置） |
| 購入基準額 | **¥480,600** |
| 患者自己負担上限 | 課税世帯: ¥37,200 / 非課税世帯: ¥0 |
| 耐用年数 | 5年（ALS等進行性疾患は状態変化時に再支給可） |
| 対象者 | 身体障害者手帳（肢体不自由1-2級 かつ 言語障害3級）、または指定難病 |
| 視線入力装置加算 | Tobii PCEye 5: ¥242,000（VoiceReachはWebカメラ方式のため該当しない可能性あり） |

**VoiceReachの場合の想定**:
- ハードウェア一式（~¥313,200）が基準額¥480,600の範囲内に収まる
- 認定取得には、テクノエイド協会への申請と、既存カテゴリ（重度障害者用意思伝達装置）への適合確認が必要
- 認定済みの場合、課税世帯でも患者負担は最大¥37,200
- **認定未取得の場合**: 日常生活用具給付等事業（市区町村）での対応を検討。申請手続きが簡易だが再支給なし

---

## 9. 各Phaseの技術スタックサマリ

| レイヤー | Phase 1 (MVP) | Phase 2 (拡張) | Phase 3 (最適化) |
|----------|---------------|----------------|------------------|
| **視線推定** | MediaPipe + MobileOne s0 + L2CS-Net (Tier 1: ≤ 2.5°) | + FAZE meta-learning 3点校正 (Tier 2: 2-3°) | + OpenFace 3.0 / foundation model (Tier 3: sub-2°) |
| **指入力** | PZT + FSR-402 + XIAO RP2040 (BOM $41) | 同左 + ADS1115高分解能ADC | + EMG/まばたき/BCI (IAL経由) |
| **ローカルLLM** | Qwen3-0.6B (Q5) + Qwen3-1.7B (Q4) via vllm-mlx | 同左 + PVPプロンプト統合 | + 先読みプリフェッチ + Qwen3-4B (M4 Max時) |
| **クラウドLLM** | Gemini 2.5 Flash (主) + Claude Haiku 4.5 (副) | 同左 + 品質ベース使い分け | + バッチAPI先読み + Gemini 3 Flash評価 |
| **TTS** | CosyVoice 2/3 (デフォルト話者) | CosyVoice 2/3 few-shot (本人の声) + GPT-SoVITS v4 | + EmoKnob感情制御 |
| **VLM** | なし | MiniCPM-V 4.0 (4.1B, Q4) + OpenCV動体検出 | + Gemini 2.5 Flash VLMフォールバック |
| **ASR** | なし | Whisper small (MLX) + Gemini 2.5 Flash | + ローカルWhisper完結 (オフライン) |
| **感情検出** | なし | 4ch (瞳孔/rPPG/視線パターン/まばたき) | + ベースライン自動更新 |
| **推論FW** | vllm-mlx + MLX | 同左 | + M5チップ最適化 |
| **患者UI** | Electron + React | 同左 + 意図軸ナビ + VLM連携 | + 長文モード + 夜間モード |
| **介護者UI** | PWA (通知 + ログ) | + YesNo質問 + サマリ + レポート | + 状態サマリ + 医師連携 |
| **デバイス** | Mac mini M4 Pro (24GB) | 同左 | + M5対応テスト + Jetsonポータブル版検討 |
| **月額API** | $5-8 | $5-8 | $5-8 (バッチAPI活用でコスト維持) |

---

## 10. 検証方法論

### 10.1 定量評価

```
A/Bテスト:
  - PVPあり vs PVPなし → 候補命中率の差
  - 意図軸分散あり vs なし → 意図到達時間の差
  - 感情フィードバックあり vs なし → 多巡ナビゲーション効率
  - 三段ハイブリッド vs クラウドのみ → 体感レイテンシの差

シングルケースデザイン:
  - ALS患者1名ごとのベースライン → 介入 → フォローアップ
  - 個人内での改善を統計的に検証（反復測定）
  - 進行度の異なる患者で横断的に比較

ベンチマーク比較:
  - SpeakFaster（Google, Nature Communications 2024）の29-60%改善をベースライン
  - 既存AAC（伝の心、OriHime eye）との通信速度比較
```

### 10.2 定性評価

```
半構造化インタビュー:
  - 患者: 使い心地、「自分らしさ」の感覚、不満点
  - 介護者: 負担感の変化、コミュニケーション品質の変化
  - 医療者: 診療への有用性、レポートの活用度

エスノグラフィー:
  - 自宅での実際の使用場面を観察
  - ビデオ記録（同意のもと）による行動分析
  - 想定外の使い方の発見
```

### 10.3 倫理審査

```
必要な倫理審査:
  - 大学または研究機関のIRB（倫理審査委員会）承認
  - 患者の同意取得プロセスの承認
  - データ取り扱いの安全性審査
  - 脆弱な集団（重度障害者）を対象とする研究の特別配慮
```

---

## 11. リスクと緩和策

| リスク | 影響 | 確率 | 緩和策 |
|--------|------|------|--------|
| Webカメラ視線推定の精度不足 | 高 | 中 | Phase 0.5で実機ベンチマーク。不合格なら IR補助LED追加 or ゾーン数削減 |
| LLM候補が的外れ（特に日本語） | 高 | 中 | 三段ハイブリッドで品質段階的向上。PVP改善 + 定型文を最終防衛線に |
| TTS音声品質 MOS < 4.0 | 中 | 中 | CosyVoice + GPT-SoVITS v4 併用。録音品質向上で改善 |
| 患者のモチベーション低下 | 高 | 中 | オンボーディング改善、初期成功体験の設計 |
| 介護者の導入抵抗 | 中 | 高 | 介護者の負担軽減を体感できるデモ、段階的導入 |
| 音声保存が間に合わない | 高 | 中 | Phase 0で先行開始。CosyVoice few-shot（5秒-）で最低限対応可 |
| プライバシー懸念 | 高 | 中 | ローカルファースト設計。VLM映像はクラウド不送信（同意時除く） |
| コスト（LLM API使用料）増大 | 中 | 低 | Gemini主体の低コスト設計。$5-8/月で十分実用的（レポートB2） |
| Apple Silicon依存リスク | 低 | 低 | llama.cpp (Metal) でクロスプラットフォーム移植可能（レポートB6） |
| 補装具費支給制度の認定不可 | 高 | 中 | 日常生活用具給付等事業で代替。テクノエイド協会への早期相談 |
| 規制（医療機器該当性） | 中 | 低 | 「日常生活用具」としての位置づけ推奨。早期に規制当局と相談 |

---

## 12. チーム構成（理想）

```
コアチーム（6名）:
  - プロダクトマネージャー（PM）: 1名
  - フロントエンドエンジニア: 1名（Electron/React + PWA）
  - MLエンジニア: 2名（視線推定 + 感情検出 + LLM/VLM統合 + TTS）
  - バックエンドエンジニア: 1名（vllm-mlx + API + インフラ）
  - ハードウェアエンジニア: 1名（指入力デバイス + カメラ設定）

アドバイザー:
  - 神経内科医
  - 言語聴覚士（ST）
  - ALS患者の家族（当事者視点）
  - HCI研究者
  - 医療倫理の専門家

Phase 2以降の追加:
  - モバイルエンジニア: 1名（介護者アプリ拡張）
  - QAエンジニア: 1名
  - デザイナー: 1名（UI/UX）
```

---

## 13. 出典

本ロードマップは以下の調査レポートに基づく:

| レポート | 主な引用内容 |
|----------|-------------|
| [A2] AAC意思伝達装置調査 | 補装具費支給制度（基準額¥480,600）、競合製品価格帯、SpeakFasterベンチマーク |
| [A6] 入力デバイス調査 | デュアルセンサ指入力BOM $41、4層フィルタリング設計 |
| [B1] ローカルLLM調査 | Qwen3シリーズ選定、量子化戦略（Q4_K_M / Q5_K_M） |
| [B2] クラウドLLM調査 | Gemini 2.5 Flash + Claude Haiku 4.5構成、月額$5-8、プロンプトキャッシュ戦略 |
| [B3] TTS調査 | CosyVoice 2/3 + GPT-SoVITS v4選定、EmoKnob感情制御 |
| [B4] 視線推定調査 | MediaPipe + MobileOne s0 + L2CS-Net、Tier 1-3精度ロードマップ |
| [B5] VLM調査 | MiniCPM-V 4.0 (4.1B)、3層ハイブリッドVLM処理 |
| [B6] エッジデバイス調査 | Mac mini M4 Pro推奨、コスト帯別構成（¥155K-¥277K）、MLXフレームワーク成熟度 |
| [B7] Input Abstraction Layer調査 | IAL設計、進行度適応入力切替 |
