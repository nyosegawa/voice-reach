# 04 — AI候補生成と意図空間ナビゲーション

## 1. 候補生成の設計思想

### 1.1 核心課題：候補の多様性

従来の予測変換が苛立たせるのは、「違う」を押しても似たような候補が出続けることである。LLMの候補生成も、そのまま使えば同じ問題を起こす。

```
悪い例（同じ意図軸の変奏）:
  1. "すごいね！"
  2. "すごいじゃん！"
  3. "それはすごいね！"
  4. "太郎すごいなぁ"
  → 全部「称賛」。言いたいのは別の方向かもしれない。
```

VoiceReachでは候補を「表現の違い」ではなく「意図の違い」で分散させる。

---

## 2. 意図軸フレームワーク

### 2.1 7つの意図軸

| 意図軸 | 説明 | 例（相手が「太郎が表彰された」と報告した場合） |
|---|---|---|
| 感情応答 | 嬉しい/驚き/感動を返す | "すごいじゃん！" |
| 質問・深掘り | もっと知りたい | "何で表彰されたの？" |
| 自分語り | 関連する自分の経験 | "俺も小学校の時なぁ" |
| 相手への言及 | 相手の気持ちや状況に触れる | "花子さんも嬉しいでしょ" |
| 行動要求 | 何かしてほしい/したい | "太郎に電話したいな" |
| ユーモア | 冗談や軽い返し | "DNAだね、俺に似たんだ" |
| 話題転換 | 別の話をしたい | "そういえば阪神どうなった？" |

### 2.2 初回候補の生成ルール

初回の4候補は、異なる意図軸から1つずつ選ぶ。

```
LLMへの指示:
  - 4つの候補はそれぞれ異なる発話意図を持つこと
  - 使用する意図軸を[タグ]で明示すること
  - 状況からの推定確率が高い意図軸を優先すること
  - ただし、低確率でも重要な軸（行動要求、緊急）は含めること
```

意図軸の選択は状況依存で変わる。

```
相手が質問してきた場合:
  → 回答系の候補を2つ + 別軸2つ

雑談の流れの場合:
  → 感情応答 + 質問 + 自分語り + ユーモア

介護者が処置に来た場合:
  → 行動要求 + 感謝 + 体調報告 + 環境要望
```

---

## 3. 多巡ナビゲーション

### 3.1 視線滞留フィードバック

候補を表示している間の視線データから、各候補への関心度を推定する。

```
視線滞留データ:
  候補A "すごいじゃん！"       → 0.3秒（チラ見）
  候補B "何で表彰されたの？"   → 1.2秒（やや長い）★
  候補C "花子さんも嬉しいでしょ" → 0.4秒
  候補D "俺も小学校の時なぁ"   → 0.5秒

解釈:
  候補Bへの関心が最も高いが、選択しなかった
  → 「質問」軸は合っているが、この質問ではない
```

### 3.2 感情シグナルの統合

視線データに加えて感情検出データを統合し、4つの判定パターンを区別する。

| パターン | 視線 | 感情信号 | 解釈 | 次の行動 |
|---|---|---|---|---|
| ヒット | 長い + タップ | ポジティブ | 選択確定 | 発話 |
| 惜しい | 長い、タップなし | ポジティブ寄り | 方向は合っている | その候補の周辺を展開 |
| 全部違う | 全て短い | ネガティブ or 無反応 | 意図軸が外れている | 別の意図軸を探索 |
| どれも微妙 | 複数を行き来 | 困惑 | 方向は合っているが表現が違う | 抽象度/温度を変えて再提示 |

### 3.3 2巡目以降の生成ロジック

```
[2巡目生成プロンプト]

前回の候補と患者の反応:
  A. "すごいじゃん！" [感情応答] → 不採用（視線0.3秒、感情:neutral）
  B. "何で表彰されたの？" [質問] → 不採用（視線1.2秒★、感情:ややpositive）
  C. "花子さんも嬉しいでしょ" [相手言及] → 不採用（視線0.4秒、感情:neutral）
  D. "俺も小学校の時なぁ" [自分語り] → 不採用（視線0.5秒、感情:neutral）

分析:
- 「質問」軸に最も関心があるが、Bでは不十分
- 未探索の意図軸: 行動要求、ユーモア、話題転換

次の候補4つを生成してください:
- 2つは「質問」軸でBとは異なる角度
- 2つは未探索の軸から
- すべて互いに意味的に遠い候補であること
```

### 3.4 バリエーション展開（ロングプレス）

特定の候補を「惜しい」と判断した場合、ロングプレスでその候補を軸にバリエーションを展開する。

```
"何で表彰されたの？" を長押し → 展開

  "何の賞もらったの？"     ← 言い換え
  "表彰式はいつ？"        ← 関連質問
  "写真ある？見たいな"     ← 同じ好奇心、別の表現
  "太郎に直接聞きたい"     ← メタ的な要求
```

---

## 4. 多様性制御の追加軸

### 4.1 抽象度スライダー

同じ意図でも抽象度を変えると全く違う候補になる。

```
「太郎の表彰」に対する質問軸:

具体的 ←──────────────────→ 抽象的

"何の教科？"  "どんな表彰？"  "最近学校どう？"  "太郎元気？"
```

初回は中間の抽象度。外れたら具体↔抽象を振る。

### 4.2 感情温度

同じ内容でも温度感を変える。

```
クール            ニュートラル          ウォーム
"ほう、表彰か"    "何で表彰されたの？"   "太郎やるなぁ！何の表彰！？"
```

### 4.3 文の長さ

短い候補と長い候補を混ぜる。

```
短: "すごい"
中: "すごいじゃん！何の表彰？"
長: "太郎すごいなぁ、花子さんに似て頭いいんだろうね"
```

---

## 5. レイヤー別の候補生成

### 5.1 Level 0: ゼロ操作候補（AI先読み）

1文字も入力しない段階で、状況コンテキストのみから候補を生成する。

```
[状況] 朝7:00 / 介護者入室 / 前回発話から6時間

  "おはよう"          [挨拶]
  "トイレお願い"       [行動要求]
  "水が欲しい"         [行動要求]
  "よく眠れたよ"       [状態報告]

推定命中率: 40〜60%
必要操作: 1回（チラ見 + タップ）
```

### 5.2 Level 1: リスニングモード候補

相手の発話を音声認識し、返答候補を自動生成する。

```
介護者: "お昼ごはん、おかゆとうどんどっちがいい？"
  ↓ ASR + LLM
自動候補:
  "おかゆ"             [選択回答]
  "うどんがいいな"      [選択回答]
  "どっちでもいいよ"    [委任]
  "まだいらない"        [拒否]

推定命中率: 70〜80%（質問への回答は選択肢が限定的）
必要操作: 1回
```

### 5.3 Level 2: カテゴリ選択

Level 0/1の候補が合わない場合。

```
  "体調"  "要望"  "会話"  "緊急"
      ↓ 「要望」を選択
  "食べ物/飲み物"  "環境"  "体勢"  "その他"
      ↓ 「環境」を選択
  "エアコン下げて"  "テレビ消して"  "カーテン開けて"  "照明変えて"

必要操作: 3回
```

### 5.4 Level 3: 2ストローク文字入力

自由文字入力が必要な場合のフォールバック。

```
操作1: 行選択（か行）
操作2: 段選択（い段）→ 「き」確定
  → LLM予測: [今日] [気持ち] [昨日] [聞いて]
操作3: 「今日」を選択
  → 文予測: [今日は調子がいい] [今日の予定は？] [今日はありがとう]
操作4: 文を選択 → 確定

必要操作: 3〜6回（予測精度次第）
```

---

## 6. 感情・トーンの付加

テキスト候補を選択した後、発話トーンを選択できる。

```
"今日は調子がいい" を選択後:

  😊 明るく    → 音声合成: 明るいトーン
  😐 普通に    → 音声合成: ニュートラル
  😔 控えめに  → 音声合成: 静かなトーン
  ❗ 強調して  → 音声合成: 力強いトーン

デフォルト: PVPの対人スタイルから自動選択
省略可: タップ2回で「普通に」で即発話
```

---

## 7. 「選ばない」が最も雄弁な入力

本システムの最重要設計思想。

従来のDwell方式では「選ばない＝何も起きない」だったが、VoiceReachでは「選ばなかったこと」自体が次の探索方向を決定する情報になる。

```
患者が明示的に操作しなくても:
  - どの候補をどれくらい見たか → 関心の方向
  - どの候補にどんな感情反応を示したか → 快不快の判定
  - 全体の視線パターン → 困惑/不満/無関心の判別

これらが自動的に次の候補生成に反映される。
患者は「違う」ボタンを押す必要すらなく、
ただ自然に画面を見ているだけでシステムが寄ってくる。
```

---

## 8. 操作負荷の比較

| 方式 | 1文の平均操作数 | 眼球移動量 | 意図到達時間 |
|---|---|---|---|
| 従来50音 Dwell | 20〜30回凝視 | 大（画面全体） | 30〜60秒 |
| ゾーン＋タップ | 10〜15回 | 中（ゾーン間移動） | 10〜20秒 |
| AI先読み＋タップ | 1〜3回 | 小（近傍のみ） | 2〜5秒 |
| リスニングモード | 1回 | 極小（方向チラ見） | 1〜2秒 |
| パッシブ検出 | 0回 | なし | 自動 |
