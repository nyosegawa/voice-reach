# VoiceReach --- ALS患者のための次世代コミュニケーションプラットフォーム

## プロジェクトビジョン

VoiceReachは、ALS（筋萎縮性側索硬化症）患者が「自分らしく」コミュニケーションを続けるための、カメラベースの統合入力システムである。

従来のアイトラッカーが抱える「眼精疲労」「専用デバイス依存」「凝視クリックの苦痛」を根本的に解消し、汎用カメラのみで動作する低コスト・低負荷のコミュニケーション環境を実現する。

本ドキュメントはプロジェクト全体の概要を示す。技術選定はすべて14本の調査レポート（Phase A/B）に基づく。

---

## 根本思想

### 「文字を打つ」から「意図を伝える」へ

ALS患者がやりたいのは文字入力ではなくコミュニケーションである。「の」「ど」「か」「わ」「い」「た」と6回操作するのと、「喉が渇いた」を1回で伝えるのでは、負担が桁違いに変わる。

VoiceReachは以下の原則で設計される:

1. **最小操作**: LLMによる先読み予測で、1--3操作で意図到達を目指す
2. **脱・凝視**: 目はポインティング、指はコンファーム。Dwell Clickを排除する
3. **個人性の保持**: 過去の文章群から抽出した Personal Voice Profile により、「その人らしい」候補を生成する
4. **進行適応**: 病状の段階に応じてシームレスにフォールバックする
5. **カメラオンリー**: 専用赤外線デバイス不要。汎用Webカメラで動作する

---

## 解決する課題

| 既存システムの課題 | VoiceReachのアプローチ |
|---|---|
| 凝視クリック（Dwell Click）による眼精疲労 | Eye + Minimal Finger ハイブリッド入力 |
| 専用デバイス（Tobii等）の高コスト・固定制約 | 汎用Webカメラ + 深層学習ベース視線推定 |
| 文字単位の遅い入力 | LLM先読み + 意図空間ナビゲーション |
| 画一的な候補（表現の多様性不足） | 意図軸分散 + 視線滞留フィードバック + 感情検出 |
| 病状進行への対応不足 | パーソナルベースライン動的再キャリブレーション |
| 「その人らしさ」の喪失 | Personal Voice Profile + In-Context Learning |

---

## システム全体構成

VoiceReachは4層アーキテクチャで構成される。詳細は [01 システムアーキテクチャ](./01_SYSTEM_ARCHITECTURE.md) を参照。

```
┌─────────────────────────────────────────────────────────┐
│ Layer 4: プレゼンテーション層                             │
│   患者UI（Electron/Web） / 介護者UI（PWA） / 管理画面    │
├─────────────────────────────────────────────────────────┤
│ Layer 3: インテリジェンス層                               │
│   三段ハイブリッドLLM推論 / 意図空間ナビゲーション / PVP  │
│   Qwen3-0.6B → Qwen3-1.7B → Gemini 2.5 Flash          │
├─────────────────────────────────────────────────────────┤
│ Layer 2: コンテキスト統合層                               │
│   VLM環境認識（MiniCPM-V 4.0） / 4ch感情推定 /          │
│   イベント検出 / 信号統合                                │
├─────────────────────────────────────────────────────────┤
│ Layer 1: センシング層                                    │
│   視線推定（MediaPipe + MobileOne s0 + L2CS-Net） /     │
│   デュアルセンサ指入力（PZT + FSR-402） / マイク / IoT   │
└─────────────────────────────────────────────────────────┘
```

### データフロー概要

```
                    ┌───────────────────┐
                    │     クラウド       │
                    │  Gemini 2.5 Flash │
                    │  Claude Haiku 4.5 │
                    └────────┬──────────┘
                             │ HTTPS（PVP + コンテキスト、匿名化済み）
                             │
┌────────────────────────────┴──────────────────────────────┐
│              患者端末（Mac mini M4 Pro, 24GB）              │
│                                                           │
│  [内向きカメラ] [外向きカメラ] [マイク] [指入力] [IoT]    │
│        │              │          │        │        │      │
│        └──────────────┴──────────┴────────┴────────┘      │
│                         ↓                                  │
│       センシングエンジン → コンテキスト統合エンジン          │
│                         ↓                                  │
│       三段ハイブリッドLLM推論 → 候補4つ生成                 │
│                         ↓                                  │
│       患者UI（チラ見 + タップで選択）                       │
│                         ↓                                  │
│       音声合成（CosyVoice 2/3、本人の声で再生）            │
│                                                           │
│  [フォールバック] 候補不一致 → ゾーン文字入力              │
└───────────────────────┬───────────────────────────────────┘
                        │ MQTT / WebSocket
           ┌────────────┴────────────┐
           │   介護者端末群            │
           │  スマホ / ウォッチ / PC   │
           └─────────────────────────┘
```

---

## 推奨ハードウェア構成

### エッジデバイス: Mac mini M4 Pro (24GB)

調査レポートB6に基づき、Apple Silicon Mac miniをメインデバイスとする。

| 項目 | 仕様 |
|------|------|
| チップ | Apple M4 Pro |
| メモリ | 24GB ユニファイドメモリ（帯域幅 273 GB/s） |
| 消費電力 | 通常動作 25--40W |
| サイズ | 12.7 x 12.7 x 5cm |
| ファン騒音 | 低負荷時ほぼ無音（~20--25dB） |
| 参考価格 | ~¥277K（税込） |

**選定理由**: MLXフレームワーク（Apple公式）が本番グレードに成熟。ユニファイドメモリによるゼロコピー転送。全パイプライン同時実行で~9--11GBに収まり、24GBで十分な余裕がある。ベッドサイド設置に最適な静音・小型設計。

### メモリ配分（全パイプライン同時実行時）

| タスク | メモリ | GPU使用率 |
|--------|--------|----------|
| 視線推定（MediaPipe + CNN） | ~0.5GB | ~10%（常時） |
| ローカルLLM（Qwen3-1.7B Q4） | ~1.2GB | ~15%（バースト） |
| ローカルLLM（Qwen3-0.6B Q5） | ~0.5GB | ~5%（バースト） |
| TTS（CosyVoice 2/3） | ~0.5--1GB | ~10%（バースト） |
| VLM（MiniCPM-V 4.0 Q4） | ~2.5GB | ~10--15%（断続） |
| OS + アプリケーション | ~4--6GB | -- |
| **合計** | **~9--11GB** | **ピーク~50%** |

### コスト帯別構成

| 構成 | デバイス | 価格帯 | 備考 |
|------|---------|--------|------|
| エントリー | Mac mini M4 (24GB) | ~¥155K | LLM ~200 tok/s |
| **推奨** | **Mac mini M4 Pro (24GB)** | **~¥277K** | **全パイプライン余裕** |
| プレミアム | Mac mini M4 Max (48GB) | ~¥400K+ | 4B以上のLLM対応可 |

### 周辺機器

| 機器 | 推奨 | 用途 |
|------|------|------|
| 内向きカメラ | 1080p Webカメラ | 視線推定・表情追跡 |
| 外向きカメラ | 広角（90度以上）720p | VLM環境認識 |
| マイク | 単一指向性USBマイク | 音声認識・話者識別 |
| 指入力デバイス | PZT + FSR-402 + XIAO RP2040 | タップ/ロングプレス（BOM ~$41） |
| ディスプレイ | 20インチ以上タッチ対応推奨 | 患者UI表示 |

---

## 技術スタック概要

14本の調査レポート（Phase A: A1--A7、Phase B: B1--B7）に基づき、各コンポーネントの技術を選定した。

| コンポーネント | 選定技術 | 根拠 |
|--------------|---------|------|
| **エッジデバイス** | Mac mini M4 Pro (24GB) | B6: MLX成熟、静音・小型、全パイプライン9--11GB |
| **推論フレームワーク** | vllm-mlx（主） / MLX（LoRA） / llama.cpp（移植用） | B6: OpenAI互換API、MLX比21--87%高速 |
| **視線推定** | MediaPipe Face Mesh + MobileOne s0 + L2CS-Net | A1, B4: 校正後2.5度、<8ms |
| **ローカルLLM** | Qwen3-0.6B (Q5) + Qwen3-1.7B (Q4) 三段ハイブリッド | B1, B2: Apache 2.0、日本語品質B+、~320 tok/s |
| **クラウドLLM** | Gemini 2.5 Flash（主） + Claude Haiku 4.5（フォールバック） | B2: TTFT最速0.28s、月額$2--3 / 品質A |
| **音声合成** | CosyVoice 2/3 + GPT-SoVITS v4 | A4, B3: ストリーミング150ms、Apache-2.0、感情制御 |
| **VLM（環境認識）** | MiniCPM-V 4.0（ローカル） + Gemini 2.5 Flash（フォールバック） | B5: GPT-4.1-mini超え、メモリ2.5GB |
| **指入力** | PZT圧電ディスク + FSR-402 デュアルセンサ + XIAO RP2040 | A6: 4層フィルタリング、BOM $41 |
| **NLP** | GiNZA v5 + SudachiPy + MeCab | PVP抽出・テキスト分析 |
| **感情推定** | 4ch統合（瞳孔径・rPPG心拍・視線パターン・まばたき） | A1, B4: パーソナルベースライン方式 |
| **音声認識** | Whisper / Google Speech-to-Text | リスニングモード・話者識別 |
| **フロントエンドUI** | Electron / Web（PWA） | 患者UI + 介護者UI |
| **IoT連携** | MQTT / Home Assistant | 環境センサー・スマートホーム |

### 三段ハイブリッドLLM推論

VoiceReachの中核技術。トリガーイベント発生から段階的に候補を表示し、ユーザーの待ち時間を知覚上ゼロに近づける。

```
トリガーイベント発生
  │
  ├─ [~150ms] Stage 1: Qwen3-0.6B（ローカル）→ 暫定候補4つ即表示
  │
  ├─ [~350ms] Stage 2: Qwen3-1.7B（ローカル）→ 改善候補で差し替え
  │
  └─ [~800ms] Stage 3: Gemini 2.5 Flash（クラウド）→ 高品質候補で差し替え
```

ユーザーが暫定候補をすぐに選んだ場合は後続Stage結果を破棄。選ばなかった場合は到着順にUIを更新する。詳細は [04 AI候補生成](./04_AI_CANDIDATE_GENERATION.md) を参照。

---

## 想定ユーザー

### プライマリユーザー
- ALS患者（発症初期 -- 完全閉じ込め状態）
- 類似の進行性神経筋疾患の患者（SMA、多系統萎縮症、筋ジストロフィー等）

### セカンダリユーザー
- 家族・介護者
- 訪問看護師・ヘルパー
- 主治医・リハビリテーション専門職
- 言語聴覚士（ST）

---

## ドキュメント構成

本プロジェクトのドキュメント群は以下の構成で管理される。

| # | ドキュメント | 概要 |
|---|---|---|
| 00 | [PROJECT_OVERVIEW（本書）](./00_PROJECT_OVERVIEW.md) | プロジェクト全体のビジョン・技術スタック概要 |
| 01 | [SYSTEM_ARCHITECTURE](./01_SYSTEM_ARCHITECTURE.md) | 4層アーキテクチャ詳細設計・ハードウェア構成・非機能要件 |
| 02 | [EYE_TRACKING_AND_INPUT](./02_EYE_TRACKING_AND_INPUT.md) | 視線推定パイプライン・デュアルセンサ指入力・IAL設計 |
| 03 | [PERSONAL_VOICE_PROFILE](./03_PERSONAL_VOICE_PROFILE.md) | PVPの抽出・構造・In-Context Learning運用 |
| 04 | [AI_CANDIDATE_GENERATION](./04_AI_CANDIDATE_GENERATION.md) | 三段ハイブリッドLLM推論・意図空間ナビゲーション |
| 05 | [EMOTION_AND_CONTEXT](./05_EMOTION_AND_CONTEXT.md) | 4ch感情推定・VLM環境認識・コンテキスト統合 |
| 06 | [CAREGIVER_INTERFACE](./06_CAREGIVER_INTERFACE.md) | 介護者側UI・エコシステム・通知設計 |
| 07 | [SAFETY_AND_EMERGENCY](./07_SAFETY_AND_EMERGENCY.md) | 緊急時通信・オフライン耐性・エラーリカバリ |
| 08 | [VOICE_PRESERVATION](./08_VOICE_PRESERVATION.md) | 音声保存プロトコル・音声合成パイプライン |
| 09 | [PRIVACY_AND_ETHICS](./09_PRIVACY_AND_ETHICS.md) | プライバシー・法的・倫理的設計 |
| 10 | [PROGRESSIVE_ADAPTATION](./10_PROGRESSIVE_ADAPTATION.md) | 進行度適応戦略・パーソナルベースライン |
| 11 | [IMPLEMENTATION_ROADMAP](./11_IMPLEMENTATION_ROADMAP.md) | 実装ロードマップ・検証計画・KPI |

---

## 非機能要件サマリ

| 項目 | 要件 |
|------|------|
| レイテンシ（候補表示） | Stage 1: 150ms / Stage 2: 350ms / Stage 3: 800ms |
| オフライン可用性 | ローカルLLM + ローカルVLMで70%以上の機能動作 |
| 消費電力 | 通常動作時25--40W |
| 月額運用コスト | クラウドAPI: $5--8（Gemini主体 + Claudeフォールバック） |
| 対応OS | macOS 15以降（推奨） / Linux / Windows（llama.cpp経由） |
| セキュリティ | 生体データはローカル保持。VLM映像は原則クラウド不送信 |

詳細は [01 システムアーキテクチャ](./01_SYSTEM_ARCHITECTURE.md) セクション9を参照。

---

## 用語定義

| 用語 | 定義 |
|---|---|
| PVP（Personal Voice Profile） | 患者の文体・語彙・思考パターンを構造化した個人プロファイル |
| 三段ハイブリッド推論 | ローカル軽量LLM→ローカルLLM→クラウドLLMの段階的推論パイプライン |
| Dwell Click | 一定時間視線を固定することでクリック操作を行う方式（VoiceReachでは排除） |
| IAL（Input Abstraction Layer） | 入力デバイスの切り替えを透過的に行う抽象化層 |
| ゾーンベース入力 | 画面をいくつかの領域に分割し、視線がどのゾーンにあるかで入力を行う方式 |
| 意図軸 | 発話意図のカテゴリ（感情応答 / 質問 / 自分語り / 行動要求等） |
| パーソナルベースライン | 個々の患者のニュートラル状態における各種生体信号の基準値 |
| rPPG | Remote Photoplethysmography。カメラ映像から心拍を推定する技術 |
| フローティングバブルUI | 視線の現在位置を中心に候補を配置するUI |
| リスニングモード | 相手の発話を音声認識し、返答候補を自動生成するモード |
| vllm-mlx | Apple Silicon向け高速LLM推論サーバー（OpenAI互換API） |
| KVキャッシュ | LLM推論で再利用可能な中間計算結果。TTFT短縮に寄与 |
