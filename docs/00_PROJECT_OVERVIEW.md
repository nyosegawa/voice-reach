# VoiceReach — ALS患者のための次世代コミュニケーションプラットフォーム

## プロジェクトビジョン

VoiceReachは、ALS（筋萎縮性側索硬化症）患者が「自分らしく」コミュニケーションを続けるための、カメラベースの統合入力システムである。

従来のアイトラッカーが抱える「眼精疲労」「専用デバイス依存」「凝視クリックの苦痛」を根本的に解消し、汎用カメラのみで動作する低コスト・低負荷のコミュニケーション環境を実現する。

---

## 根本思想

### 「文字を打つ」から「意図を伝える」へ

ALS患者がやりたいのは文字入力ではなくコミュニケーションである。「の」「ど」「か」「わ」「い」「た」と6回操作するのと、「喉が渇いた」を1回で伝えるのでは、負担が桁違いに変わる。

VoiceReachは以下の原則で設計される：

1. **最小操作**: LLMによる先読み予測で、1〜3操作で意図到達を目指す
2. **脱・凝視**: 目はポインティング、指はコンファーム。Dwell Clickを排除する
3. **個人性の保持**: 過去の文章群から抽出した Personal Voice Profile により、「その人らしい」候補を生成する
4. **進行適応**: 病状の段階に応じてシームレスにフォールバックする
5. **カメラオンリー**: 専用赤外線デバイス不要。汎用Webカメラで動作する

---

## 解決する課題

| 既存システムの課題 | VoiceReachのアプローチ |
|---|---|
| 凝視クリック（Dwell Click）による眼精疲労 | Eye + Minimal Finger ハイブリッド入力 |
| 専用デバイス（Tobii等）の高コスト・固定制約 | 汎用Webカメラ + 深層学習ベース視線推定 |
| 文字単位の遅い入力 | LLM先読み + 意図空間ナビゲーション |
| 画一的な候補（表現の多様性不足） | 意図軸分散 + 視線滞留フィードバック + 感情検出 |
| 病状進行への対応不足 | パーソナルベースライン動的再キャリブレーション |
| 「その人らしさ」の喪失 | Personal Voice Profile + In-Context Learning |

---

## システム全体構成

```
┌──────────────────────────────────────────────────────┐
│                    データ層                           │
│  過去データ → 抽出パイプライン → PVP（個人プロファイル）│
│  音声録音 → 声質保存 → 音声合成モデル                 │
└────────────────────────┬─────────────────────────────┘
                         │
┌────────────────────────┴─────────────────────────────┐
│                  リアルタイム層                        │
│                                                      │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌──────────┐  │
│  │内向きCam │ │外向きCam│ │  マイク  │ │IoT/予定表│  │
│  │視線+表情 │ │人物+物体│ │音声認識  │ │環境+予定 │  │
│  └────┬────┘ └────┬────┘ └────┬────┘ └─────┬────┘  │
│       └──────────┬──┴──────────┘             │       │
│                  ↓                           │       │
│         コンテキスト統合エンジン ←────────────┘       │
│           (イベントドリブン更新)                       │
│                  ↓                                   │
│     PVP + コンテキスト → LLM → 候補生成（多軸分散）   │
│                  ↓                                   │
│           フローティングUI                            │
│         チラ見 + タップで選択                          │
│                  ↓                                   │
│        音声合成（本人の声 + トーン制御）               │
│                                                      │
│  [フォールバック]                                     │
│    候補不一致 → ゾーン文字入力 → 2ストローク方式       │
└──────────────────────────────────────────────────────┘
```

---

## ドキュメント構成

本プロジェクトのドキュメント群は以下の構成で管理される。

| # | ドキュメント | 概要 |
|---|---|---|
| 00 | PROJECT_OVERVIEW（本書） | プロジェクト全体のビジョンと構成 |
| 01 | SYSTEM_ARCHITECTURE | システムアーキテクチャ詳細設計 |
| 02 | EYE_TRACKING_AND_INPUT | 視線推定・入力インターフェース設計 |
| 03 | PERSONAL_VOICE_PROFILE | 個人プロファイル（PVP）の抽出と活用 |
| 04 | AI_CANDIDATE_GENERATION | AI候補生成と意図空間ナビゲーション |
| 05 | EMOTION_AND_CONTEXT | 感情検出・外部環境認識・コンテキスト統合 |
| 06 | CAREGIVER_INTERFACE | 介護者側インターフェースとエコシステム |
| 07 | SAFETY_AND_EMERGENCY | 緊急時通信・オフライン耐性・エラーリカバリ |
| 08 | VOICE_PRESERVATION | 音声保存プロトコルと音声合成 |
| 09 | PRIVACY_AND_ETHICS | プライバシー・法的・倫理的設計 |
| 10 | PROGRESSIVE_ADAPTATION | 進行度適応戦略・パーソナルベースライン |
| 11 | IMPLEMENTATION_ROADMAP | 実装ロードマップ・検証計画・KPI |

---

## 想定ユーザー

### プライマリユーザー
- ALS患者（発症初期〜完全閉じ込め状態）
- 類似の進行性神経筋疾患の患者（SMA、多系統萎縮症、筋ジストロフィー等）

### セカンダリユーザー
- 家族・介護者
- 訪問看護師・ヘルパー
- 主治医・リハビリテーション専門職
- 言語聴覚士（ST）

---

## 技術スタック概要

| コンポーネント | 技術候補 |
|---|---|
| 視線推定 | MediaPipe Face Mesh + 軽量CNN（Appearance-based） |
| 表情/感情検出 | MediaPipe 468点ランドマーク + rPPG + パーソナルベースライン |
| 候補生成（クラウド） | Claude / GPT-4o 等のLLM API |
| 候補生成（オンデバイス） | Llama 3 / Phi-3 等の軽量LLM |
| 音声認識 | Whisper / Google Speech-to-Text |
| 外部環境認識 | VLM（Vision-Language Model） |
| 音声合成 | XTTS / VALL-E / StyleTTS 等のゼロショット音声合成 |
| フロントエンドUI | Web技術（React / Electron） |
| 指入力センサー | ピエゾ素子 / 静電容量タッチ（USB HID接続） |
| IoT連携 | MQTT / Home Assistant |

---

## 用語定義

| 用語 | 定義 |
|---|---|
| PVP（Personal Voice Profile） | 患者の文体・語彙・思考パターンを構造化した個人プロファイル |
| Dwell Click | 一定時間視線を固定することでクリック操作を行う方式 |
| ゾーンベース入力 | 画面をいくつかの領域に分割し、視線がどのゾーンにあるかで入力を行う方式 |
| 意図軸 | 発話意図のカテゴリ（感情応答/質問/自分語り/行動要求等） |
| パーソナルベースライン | 個々の患者のニュートラル状態における各種生体信号の基準値 |
| rPPG | Remote Photoplethysmography。カメラ映像から心拍を推定する技術 |
| フローティングバブルUI | 視線の現在位置を中心に候補を配置するUI |
| リスニングモード | 相手の発話を音声認識し、返答候補を自動生成するモード |
