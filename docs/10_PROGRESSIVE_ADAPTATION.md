# 10 --- 進行度適応戦略・パーソナルベースライン

## 1. ALS進行の概要とシステム適応

### 1.1 ALSの典型的な進行パターン

```
Stage 1: 初期（発症〜1-2年）
  - 四肢の一部に筋力低下
  - 指の巧緻性がやや低下（ALSFRS-R Handwriting 4-3）
  - 発話は正常〜軽度の構音障害
  - 表情筋はほぼ正常

Stage 2: 中期（1-3年）
  - 筋力低下の広がり
  - 指の動きが微小化（ALSFRS-R Handwriting 2）
  - 構音障害の進行
  - 表情筋の部分的低下

Stage 3: 進行期（2-5年）
  - 四肢の随意運動がほぼ消失（ALSFRS-R Handwriting 1-0）
  - 指の微小な動きのみ残存、またはEMG信号のみ
  - 発話不能
  - 表情筋の著しい低下、眼球運動は残存

Stage 4: TLS（Totally Locked-in State）
  - 全随意運動の消失
  - 眼球運動も低下
  - コミュニケーション手段が極めて限られる

※進行速度には大きな個人差がある
※球麻痺型（Bulbar onset）では舌・口腔機能の低下が先行する
```

### 1.2 VoiceReachの適応マッピング

| 患者の状態 | 主入力方式 | フォールバック入力 | 候補生成 | 感情検出 | 音声出力 |
|---|---|---|---|---|---|
| Stage 1 | 視線+指タップ（フル） | --- | AI先読み（4候補・意図軸分散） | 全チャネル（瞳孔+rPPG+視線+表情） | 本人の声（生） |
| Stage 2 | 視線+指タップ（感度UP）+EMG補完 | まばたき入力 | AI先読み+リスニング | 瞳孔+rPPG+視線+まばたき中心 | 本人の声（生→合成切替） |
| Stage 3 | 視線+まばたき or EMG微弱信号 | 視線のみ（滞留+まばたき確認） | リスニング+パッシブ重視 | 瞳孔+rPPG+視線パターン中心 | 音声合成 |
| Stage 4 | まばたき or BCI（P300+LLM） | パッシブのみ（YesNo） | パッシブ重視+YesNo | 瞳孔+rPPG中心（自律神経系） | 音声合成 |

---

## 2. Input Abstraction Layer（IAL）と入力チャネルの段階的移行

VoiceReachはInput Abstraction Layer（IAL）を導入し、すべての入力デバイスを統一イベントインターフェース（SELECT, CONFIRM, CANCEL, EMERGENCY, SCROLL）に抽象化する（レポートA6, B7; アーキテクチャ設計 `docs/01_SYSTEM_ARCHITECTURE.md`）。

```
                    +-------------------------------+
                    |   Input Abstraction Layer      |
                    |   統一イベントインターフェース   |
                    +---------------+---------------+
          +----------+----------+---+---+---------+----------+
          v          v          v       v         v          v
    指タップ      まばたき      EMG      BCI       音声     視線ジェスチャー
   (Stage 1-3)  (Stage 3-4)  (Stage 2-4) (Stage 4) (残存発声) (Stage 3-4)
```

IALの設計原則:
1. **統一イベント**: すべての入力ソースは同じイベント型に変換される
2. **ホットスワップ**: 入力ソースの切替は再起動不要で行える
3. **併用モード**: 複数の入力ソースを同時に使用し、信頼度スコアの重み付け合成が可能
4. **進行度連動**: パーソナルベースラインの変化に応じて自動的に入力ソースの重み付けを調整
5. **プラグイン方式**: 新しい入力デバイスはアダプターの追加のみで統合可能

### 2.1 IAL Tier遷移の判定基準

IALは以下の4段階の入力ティアで構成され、パーソナルベースラインの変化に基づいて自動的に遷移を判定する。

```
Tier A: 指タップ（Stage 1-3）
  │
  │ 遷移判定: 30日移動平均タップ振幅がベースラインの30%以下
  │          AND 週次リジェクト率 > 40%
  │          AND 連続3週間の低下傾向
  │
  ├→ Tier B-1: まばたき入力（Stage 3-4）
  │   追加ハードウェア不要（MediaPipe EARで実現）
  │   遷移判定: まばたき検出信頼度 > 85%かつ意図的/自然まばたき分類精度 > 90%
  │
  ├→ Tier B-2: EMG微弱信号（Stage 2-4）※Tier Aと併用可
  │   「指を動かす意図」のMU発火を検出（振幅 <10uV）
  │   遷移判定: EMG信号S/N比 > 3.0 が安定して維持される場合に有効
  │
  │ 遷移判定（Tier B → Tier C）:
  │   眼球運動範囲がベースラインの50%以下
  │   AND まばたき検出信頼度 < 70%（3週連続）
  │
  └→ Tier C: BCI（Stage 4・TLS）
      P300+LLM（ChatBCI方式）またはfNIRS-BCI
      専門医療機関との連携が必要
```

**遷移はすべて双方向**: 体調の良い日に上位ティアに一時的に復帰することも許容する（セクション6.2参照）。

### 2.2 Tier A: 指タップ入力の適応

デュアルセンサ指入力（PZT圧電ディスク + Interlink FSR-402）の詳細はレポートA6を参照。

```
[感度の自動調整]

  患者のタップ圧力を継続的にモニタリング
  ↓
  過去30日の圧力分布を算出
  ↓
  圧力が低下傾向 → 閾値を自動で下方修正
  ↓
  最小圧力が閾値に近づく → アラート
  → センサー装着位置の変更を提案（指先→母指球→手背→前腕→頬）
  → まばたき入力への準備を開始

[不随意運動フィルタの進化]（レポートA6 Section 6）

  Stage 1: デバウンス 100ms, 波形テンプレートマッチング OFF, 視線ゲーティング重み 0.3
  Stage 2: デバウンス 150ms, 波形テンプレートマッチング ON,  視線ゲーティング重み 0.5
  Stage 3: デバウンス 200ms, 波形テンプレートマッチング ON,  視線ゲーティング重み 0.7
           + ADS1115 外部ADC（16bit）による高分解能計測を有効化

[センサー装着位置の移行経路]（レポートA6 Section 7.2）

  Stage 1: 指先 → 最大の巧緻性、自然なタップ動作
    ↓
  Stage 2: 母指球 → 母指は他の指より筋力が長く残存する傾向
    ↓
  Stage 2b: 手背 → 手首伸展/屈曲を検出
    ↓
  Stage 3: 前腕 → 残存する前腕筋の収縮を検出
    ↓
  Stage 3b: 頬/こめかみ → 咬筋収縮や眉の動きを検出
    ↓
  Stage 4: 指タップ入力を無効化 → Tier B以降に移行
```

### 2.3 Tier B-1: まばたき入力

指入力が不能になった場合の第一フォールバック。追加ハードウェア不要（レポートB7）。

```
検出技術:
  MediaPipe Face Meshの468点ランドマーク → EAR（Eye Aspect Ratio）計算
  精度: 98.03%（Eyeblink 8データセット）（レポートB7 RQ3）
  3Dランドマーク方式により頭部傾斜への耐性あり

ジェスチャーマッピング:
  シングルまばたき（強い意図的まばたき）
    → 選択確定（IAL: CONFIRM）

  ダブルまばたき（0.5秒以内に2回）
    → 戻る/キャンセル（IAL: CANCEL）

  ロングクローズ（2秒以上の閉眼）
    → メニュー/バリエーション展開（IAL: SCROLL）

  トリプルまばたき（1秒以内に3回）
    → 緊急コール（IAL: EMERGENCY）

課題と対策:
  課題: 通常のまばたきと意図的まばたきの区別
  対策: 「強いまばたき」のパターンを個人学習（閉眼持続時間・EAR低下速度の閾値を個人最適化）

  課題: まばたきの検出精度（閉眼中は視線追跡不能）
  対策: まばたき検出と視線追跡の時分割処理

  課題: 操作速度の低下（まばたきはタップより遅い）
  対策: AI候補生成への依存度を上げ、操作回数を最小化（1巡目命中率70%以上を目標）
```

### 2.4 Tier B-2: EMG微弱信号入力

指が物理的に動かなくても「動かそうとする意図」に伴う微弱なEMG信号（運動単位発火）は残存する場合がある。指タップの代替/補完として自然に統合可能（レポートB7 RQ2, RQ7）。

```
推奨デバイス:

  [短期] OYMotion gForcePro+
    - 8ch sEMG, 500Hz (12bit) / 1kHz (8bit)
    - 価格: $90-150
    - BLE接続, クラウドAIジェスチャー学習
    - ALS Stage 1-2での利用に適する

  [中期] Meta Neural Band
    - 16ch sEMG
    - 価格: $799（Meta Ray-Ban Display AR眼鏡込み）
    - 2025年9月発売（レポートB7 RQ2）
    - 個人キャリブレーション不要のユニバーサルデコード
      （200,000人の研究参加者データに基づく, Nature誌発表）
    - タップ、スワイプ、ピンチ等のジェスチャー認識
    - ALS Stage 1-3での利用に最も有望

ALS患者のEMG信号の経時変化:
  初期〜中期（発症後1-3年）: 残存筋力で十分な信号振幅（>50uV）
  中期〜後期（3-5年）: 信号振幅が著しく低下（<10uV）→ 高感度アンプ+適応フィルタ必要
  後期（5年以上）: 表面EMGでは検出困難 → BCIまたは他の入力に移行

IALへの統合:
  EMGセンサーアダプタ → 閾値ベースの二値入力（筋活動あり/なし）
  → IAL CONFIRM イベントとして発行
  パーソナルベースラインの概念をEMG信号にも適用（信号振幅のトレンド監視）
```

### 2.5 視線入力の適応

```
[ゾーン数の動的調整]

  追跡精度が安定 → 9〜16ゾーン（細かい操作可能）
  精度がやや低下 → 4〜9ゾーン
  精度が大幅低下 → 2〜4ゾーン
  追跡不能       → まばたきのみ

[眼球運動範囲の適応]

  眼球運動が十分 → 画面全体を使用
  運動範囲が縮小 → UIを中央に集約
  ほぼ正面のみ   → 正面の小さな領域にUI配置

[視線ジェスチャー入力]（Stage 3-4、指タップなしのフォールバック）

  滞留時間の閾値を動的調整（Dwell Click回避のため、0.5秒滞留+まばたき確認の組み合わせ）
  視線の「うなずき」パターン（上→下の視線移動）を確定操作に割り当て
```

---

## 3. 各ステージでの推奨入力方式一覧

| Stage | 主入力 | 補助入力 | 推奨デバイス | 追加コスト |
|-------|--------|----------|-------------|-----------|
| Stage 1 | 視線+指タップ（PZT+FSR） | 音声（残存発声） | Webカメラ + XIAO RP2040デュアルセンサ（BOM $41） | ~$50（カメラ） |
| Stage 2 | 視線+指タップ（感度UP） | EMG補完 | + OYMotion gForcePro+（$90-150）or Meta Neural Band（$799） | $90-799 |
| Stage 3 | 視線+まばたき | EMG微弱信号 or 指タップ（前腕/頬） | 追加なし（カメラベースまばたき検出）+ EMGセンサー | $0-799 |
| Stage 4-TLS | まばたき or BCI | パッシブ（YesNo） | Emotiv Insight（$499）or g.tec Unicorn（~$1,200）| $499-1,200 |

**日本の福祉補助金との整合**（レポートA6 Section 3）:
- 圧電素子式入力装置: 補助基準額 JPY 53,400
- 筋電式入力装置: 補助基準額 JPY 85,400（EMGデバイスが対象）
- 帯電式入力装置: 補助基準額 JPY 42,700
- VoiceReachのデュアルセンサ（BOM $41 = ~JPY 6,000）は圧電素子式の補助範囲内

---

## 4. 将来ロードマップ: BCI統合（Tier C）

### 4.1 ChatBCI: P300+LLM統合（レポートB7 RQ1）

2025年にNature Scientific Reportsで発表されたChatBCIは、VoiceReachのLLM先読み設計思想と極めて近い。

```
ChatBCIの成果:
  - P300スペラーにLLMの文脈予測を統合
  - キーストローク数を53.22%削減
  - 情報伝達速度（ITR）を229.48%向上

VoiceReachとの統合構想:
  EEGデバイス（Emotiv Insight $499 or g.tec Unicorn ~$1,200）
    ↓
  P300/SSVEP信号処理（MNE-Python or MetaBCI）
    ↓
  VoiceReachの三段ハイブリッドLLM推論エンジン
    ↓
  P300で選択 → LLMが候補を生成 → P300で確定
  → 1文字ずつではなく「意味単位」での選択が可能に

対象Stage: Stage 4（眼球運動の低下時）
実装時期: Phase 3以降（研究段階から臨床段階への移行を待つ）
```

### 4.2 fNIRS-BCI（レポートB7 RQ1）

```
技術概要:
  - 近赤外光で脳血流変化（酸素化ヘモグロビン濃度変化）を計測
  - ALS患者での精度: 81.3% +/- 5.7%（P300-BCIの74.0% +/- 8.9%を上回る）
  - EEG+fNIRSマルチモーダル統合で分類精度90.11%を達成した報告あり
  - 「BCI illiteracy」問題（個人によりBCIが使えない問題）への耐性が高い

主要デバイス:
  - Kernel Flow: 52モジュール、TD-fNIRS技術、重量2.05kg（研究機関向け）

VoiceReachへの統合見通し:
  - 現時点では研究段階。商用ポータブルデバイスの登場を待つ
  - 完全閉じ込め状態（CLIS）における最も有望な選択肢の一つ
  - EEG+fNIRSデュアルストリームモデル（E-FNet等）の成熟を監視する
```

### 4.3 侵襲型/低侵襲型BCI（長期監視対象）

```
Synchron Stentrode:
  - 血管内留置型BCI（開頭手術不要）
  - 2025年8月: ALS患者がiPadのSwitch Controlを思考のみで操作に成功
  - 10名の患者で安全性を確認。$200M Series D調達
  - VoiceReachとの統合: 商用化後のAPI連携を検討

Neuralink N1:
  - 2024年1月に初の被験者に埋め込み、1,024電極
  - 2026年1月時点で21名に拡大
  - VoiceReachの「カメラオンリー」哲学とは方向性が異なるが、TLS患者には検討対象

日本国内:
  - JiMED社（大阪大学発）: 埋め込み型BCI装置。2028年実用化目標
  - 産総研ニューロコミュニケーター: P300ベース。VoiceReachのLLM統合と組み合わせ可能
```

---

## 5. 感情検出チャネルの動的管理

### 5.1 チャネル構成とALS進行対応（レポートA5）

VoiceReachの感情推定は4チャネル構成を基本とする。ALS患者において瞳孔の自律神経制御は特徴的に温存されるため（Int. J. Mol. Sci., 2022; レポートA5 RQ1）、瞳孔径チャネルはTLS段階まで利用可能である。

```
チャネル別の利用可能期間:

  瞳孔径変化:    Stage 1〜4（自律神経制御が温存されるため最後まで有効）
  rPPG心拍変動:  Stage 1〜4（顔面血流があれば検出可能）
  視線パターン:   Stage 1〜3（眼球運動が残存する限り有効）
  まばたきパターン: Stage 1〜3（自然まばたきの頻度/持続時間変化）
  顔面ランドマーク微変化: Stage 1〜2（表情筋の衰退に伴い無効化）
  入力パターン:   Stage 1〜3（選択速度、キャンセル頻度等の行動指標）
```

### 5.2 チャネル信頼性の自動評価

```
月次で各チャネルの「有効性」を評価する。

評価方法:
  1. 過去30日間の各チャネルの信号振幅を算出
  2. パーソナルベースラインとの比較で「変化検出力」を定量化（z-score）
  3. S/N比が閾値以下 → チャネルを「低信頼」に降格
  4. 3ヶ月連続で低信頼 → チャネルを「無効」に設定
  5. 無効化されたチャネルの重みを残存チャネルに再配分

重み再配分の例:

  [初期（Stage 1）]              [24ヶ月後（Stage 3）]
  瞳孔径:      重み 0.20  →     重み 0.30 (+)
  rPPG:        重み 0.15  →     重み 0.25 (+)
  視線パターン:  重み 0.15  →     重み 0.20 (+)
  まばたき:     重み 0.15  →     重み 0.20 (+)
  顔面ランドマーク: 重み 0.20  →  重み 0.00 (無効)
  入力パターン:  重み 0.15  →     重み 0.05 (低信頼)
```

### 5.3 パーソナルベースラインの進行対応メカニズム（レポートA5 RQ5）

ベースライン相対アプローチは、個人の安静時からの微小な偏差を検出する手法であり、ALS患者のように個人差と経時変化が大きい対象に対して特に有効である。

```
[3層ベースライン構成]

  Layer 1: 静的ベースライン（初期キャリブレーション時に取得）
    - 安静時5分間の全チャネル計測
    - 快/不快/興味/退屈の各刺激への反応パターン
    - 初回のみ実施。以降はLayer 2/3で動的に更新

  Layer 2: 動的ベースライン（日次〜週次で自動更新）
    - 日次: 当日の各チャネル統計値を記録。疲労パターンの時間帯別プロファイル更新
    - 週次: 日次データの傾向分析。異常値の検出とフラグ付け

  Layer 3: 進行適応ベースライン（月次〜四半期で見直し）
    - 月次: チャネル信頼性スコアの再計算、重み配分の更新、閾値の再調整
    - 四半期: 半年間のトレンド分析、機能レベルの見直し、入力方式の変更提案

[ベースラインドリフトへの対応]

  ALS進行に伴い、各チャネルの信号振幅が経時的に縮小する。

  検出方法:
    weekly_amplitude = 過去7日間の信号振幅中央値
    trend = linear_regression(直近12週の weekly_amplitude)

    if trend.slope < -0.05:  # 緩やかな低下
      → 閾値を自動で下方修正（感度UP）
      → 管理ダッシュボードに「緩やかな変化」として記録

    if trend.slope < -0.15:  # 急速な低下
      → 介護者に通知:「感情推定の精度が変化しています」
      → 医師向けレポートに記録
      → 残存チャネルでの推定精度を再評価

    if weekly_amplitude < baseline * 0.1:  # ほぼ消失
      → チャネルを「低信頼」に降格
      → 3ヶ月継続で「無効」に設定
      → 残存チャネルへの重み再配分を実行
```

### 5.4 移行アラートと家族への通知

```
チャネル無効化時:
  1. 管理ダッシュボードに通知
  2. 介護者に平易な日本語で説明
  3. 医師向けレポートに記録
  4. 残存チャネルでの推定精度を表示

例: "口角の動きによる感情推定が困難になりました。
     現在は瞳孔の変化・心拍の変化・目の動きパターンを中心に
     感情を推定しています。推定精度はやや低下しますが、
     瞳孔反応はALSの進行によらず維持される傾向があります。"
```

---

## 6. 候補生成戦略の進行度適応

### 6.1 Stage別の候補生成方針

```
Stage 1（操作余力あり）:
  - 4候補を意図軸分散で提示
  - 多巡ナビゲーションをフル活用
  - 自由入力も積極的に使用
  - 長文モードも利用可能
  - 命中率目標: 40〜60%（2巡程度で到達）

Stage 2（操作余力が限定的）:
  - 4候補の命中率を重視（冒険的な候補を減らす）
  - リスニングモードの使用頻度を上げる
  - 定型文のカスタマイズを充実
  - 命中率目標: 55〜70%（1.5巡程度で到達）

Stage 3（最小限の操作）:
  - 2〜3候補に削減（選択肢の認知負荷を下げる）
  - リスニングモード中心
  - パッシブ検出の活用
  - 緊急候補を常に表示
  - 命中率目標: 70〜80%（1巡で到達）
  → 多様性を犠牲にしても確実性を優先
  → 状況コンテキストへの依存度UP
  → PVPの頻出パターンを優先

Stage 4（TLS）:
  - YesNo方式を中心
  - パッシブ感情検出による状態推定
  - 介護者主導のコミュニケーション支援
  - BCI連携時: ChatBCI方式でLLM候補から選択
```

### 6.2 「いい日/悪い日」への対応

ALS患者の状態は日によって変動する。

```
体調が良い日:
  - 操作の反応速度が向上
  - 視線追跡精度が向上
  - まばたき頻度が安定
  → システムは自動的にゾーン数を増やす等の最適化
  → 一時的に上位Tierの入力方式に復帰可能

体調が悪い日:
  - 反応速度の低下
  - 視線のブレが増加
  - 疲労の早期出現
  → ゾーン数削減、候補数削減、休憩提案の頻度UP
  → 定型文モードへの切替を早期に提案
  → 下位Tierの入力方式へ一時的にフォールバック

検出方法:
  セッション開始時の最初の数回の操作で
  その日の状態を推定し、パラメータを動的調整
  （直近5回の操作の反応時間・精度を過去7日平均と比較）
```

---

## 7. オンボーディング設計

### 7.1 導入フロー

```
Day 1: 最小セットアップ（30分）
  - カメラの設置と視線キャリブレーション
  - 指センサーの装着と感度調整（PZT+FSR デュアルセンサ）
  - 基本操作の説明（チラ見+タップ、ダブルタップ）
  - 定型文10件の登録（最もよく使うフレーズ）
  → この日から基本的なコミュニケーションが可能

Week 1: 基本機能の習熟
  - 毎日10〜15分の練習セッション
  - ゾーン選択の精度向上
  - 候補選択の操作に慣れる
  - 疲労度に応じた休憩の取り方を学ぶ

Week 2-3: PVP構築と高度機能
  - データソースの接続（Gmail, LINE等）
  - PVPの初期生成と確認
  - リスニングモードの有効化
  - 介護者アプリのセットアップ
  - パーソナルベースライン初期キャリブレーション（感情検出用, 30分）

Month 2: 最適化
  - PVPの微調整（「こう言わない」等のフィードバック）
  - 候補命中率のモニタリングと改善
  - パーソナルベースラインの初回確立（4週間のデータ蓄積後）
  - 定型文の追加・修正
```

### 7.2 段階的機能開放

```
Level 1（初日〜）:
  - 定型文選択
  - 基本文字入力
  - 緊急コール

Level 2（1週間後〜）:
  - AI候補生成
  - フローティングバブルUI
  - 介護者通知

Level 3（2週間後〜）:
  - リスニングモード
  - PVP活用候補
  - 意図軸ナビゲーション

Level 4（1ヶ月後〜）:
  - パッシブ感情検出
  - 環境認識統合
  - 長文モード
  - 音声合成（本人の声）
```

### 7.3 既存装置からの移行

```
伝の心/レッツチャットからの移行:
  - 既存の定型文セットをインポート
  - 操作体系の違いを丁寧に説明
  - 並行使用期間を設ける（2週間程度）
  - 既存装置をバックアップとして残す

Tobii PCEyeからの移行:
  - Dwell Click → チラ見+タップ への操作変更
  - 視線追跡精度の違い（専用機→Webカメラ）に注意
  - ゾーンベース設計の利点を体験してもらう
  - 精度に不満がある場合はゾーン数を減らして対応
```

### 7.4 介護者の同時オンボーディング

```
介護者が学ぶべきこと:
  1. 患者が操作中に邪魔しない配慮
     - カメラの前を横切らない
     - 操作中に話しかけるタイミング
  2. 介護者アプリの操作
     - 通知の確認方法
     - YesNo質問モードの使い方
  3. トラブルシューティング
     - キャリブレーションの再実行方法
     - システムの再起動方法
     - センサー装着位置の変更手順（Stage進行時）
  4. 感情データの解釈
     - 数値の見方
     - 過度に依存しない（あくまで参考値）
  5. 入力方式の移行時の対応
     - まばたき入力への切替時の練習サポート
     - EMGセンサーの装着サポート
```

---

## 8. パーソナルベースラインの運用

### 8.1 ベースライン更新サイクル

```
日次:
  - その日の各チャネルの統計値を記録
  - 疲労パターンの時間帯別プロファイルを更新
  - 入力パターン（タップ振幅、反応時間、リジェクト率）の記録

週次:
  - 日次データの傾向分析
  - 異常値の検出とフラグ付け
  - タップ振幅トレンドの回帰分析（decline検出）

月次:
  - チャネル信頼性スコアの再計算
  - 重み配分の更新
  - 閾値の再調整
  - 管理ダッシュボードに進行レポートを出力
  - IAL Tier遷移の判定（セクション2.1の基準に基づく）

四半期:
  - 半年間のトレンド分析
  - 機能レベルの見直し
  - 入力方式の変更提案（必要な場合）
  - 医療チームへのレポート提出
```

### 8.2 進行検出とアクション

```
[自動進行検出のフロー]

  日次データ蓄積
    ↓
  週次トレンド分析
    ├→ タップ振幅低下傾向を検出 → 指入力感度UP + センサー位置変更提案
    ├→ 視線追跡精度低下を検出 → ゾーン数削減 + UI中央集約
    ├→ まばたき検出精度低下を検出 → BCI準備の提案
    └→ 感情チャネルの振幅縮小を検出 → 閾値下方修正 + 重み再配分
    ↓
  月次IAL Tier遷移判定
    ├→ 遷移不要 → 現状維持
    ├→ Tier A → Tier B → 介護者に通知、まばたき入力の練習を開始
    ├→ Tier B → Tier C → 専門医療機関との連携を推奨
    └→ 一時的復帰 → 上位Tierを「利用可能」として併用モードに設定

[介護者・医療チームへの通知レベル]

  INFO:  パラメータの自動調整が行われた（ログのみ）
  NOTICE: 感度やゾーン数の変更が行われた（ダッシュボードに表示）
  ALERT:  入力方式の移行が推奨される（介護者に通知）
  CRITICAL: Tier遷移が実行された/医師への相談を推奨（全関係者に通知）
```

---

## 9. 出典一覧

| 参照 | 内容 | 出典 |
|------|------|------|
| レポートA5 | 感情検出技術調査（rPPG、瞳孔径、ベースラインアプローチ） | `research/phase_a/a5_emotion_detection/report.md` |
| レポートA6 | 指圧入力・センサー・IAL・ステージ別適応 | `research/phase_a/a6_finger_pressure_input/report.md` |
| レポートB7 | BCI・EMG・まばたき検出・フォールバック優先順位 | `research/phase_b/b7_input_devices/report.md` |
| ChatBCI | P300+LLM統合BCI | Nature Scientific Reports, 2025 (B7 #8) |
| Meta Neural Band | 16ch sEMG、$799、2025年9月発売 | Meta / Nature, 2025 (B7 RQ2) |
| fNIRS-BCI精度 | ALS患者81.3%、EEG+fNIRS統合90.11% | PLOS ONE, 2025 (B7 #27) |
| 瞳孔自律神経温存 | ALSにおける瞳孔制御の温存 | Int. J. Mol. Sci., 2022 (A5 #16) |
| まばたき検出精度 | EAR方式 98.03% | Springer, 2024 (B7 #18) |
| ALSFRS-R | ALS機能評価尺度と入力能力の対応 | A6 Section 7.1 |
| 福祉補助金 | 圧電素子式 JPY 53,400、筋電式 JPY 85,400 | A6 Section 3 |
