# B2 -- クラウドLLM調査レポート

**調査日**: 2026-02-17
**対象**: VoiceReach 二段構成推論の Stage 2（高品質応答）に最適なクラウドLLMの選定

---

## 1. エグゼクティブサマリー

VoiceReachのStage 2推論は、ローカルLLMが暫定候補を表示した後、1-2秒以内に高品質な4候補を生成してUIを更新する。PVP（Personal Voice Profile）を含む約3500トークンのプロンプトを処理し、意図軸分散を遵守した日本語候補を生成する能力が求められる。

調査の結果、**Gemini 2.5 Flash をプライマリプロバイダー、Claude Haiku 4.5 をセカンダリプロバイダー**とする構成を推奨する。Gemini 2.5 Flashは圧倒的なコスト効率とレイテンシ性能を持ち、日常の大量呼び出しに最適。Claude Haiku 4.5は指示追従能力と日本語品質に優れ、高品質が求められる場面でのフォールバックに適している。

---

## 2. プロバイダー比較マトリクス

### 2.1 主要モデル比較（2026年2月時点）

| 項目 | Claude Haiku 4.5 | Claude Sonnet 4.5 | GPT-4o mini | GPT-4.1 nano | Gemini 2.5 Flash | Gemini 3 Flash |
|---|---|---|---|---|---|---|
| **入力単価** (/1M tok) | $1.00 | $3.00 | $0.15 | $0.10 | $0.30 | $0.50 |
| **出力単価** (/1M tok) | $5.00 | $15.00 | $0.60 | $0.40 | $2.50 | $3.00 |
| **TTFT** | 0.49s | 0.8-1.0s | 0.35s | 0.37s | 0.28s | ~0.3s |
| **出力速度** (tok/s) | 108-128 | ~77 | ~100 | ~99 | ~285 | ~218 |
| **コンテキスト長** | 200K | 200K | 128K | 1M | 1M | 1M |
| **最大出力** | 64K | 64K | 16K | 16K | 65K | 65K |
| **ストリーミング** | 対応 | 対応 | 対応 | 対応 | 対応 | 対応 |
| **日本語品質** | A | A+ | B+ | B | A- | A |
| **指示追従** | A+ | A+ | A | A | A | A+ |
| **プロンプトキャッシュ** | 対応 | 対応 | 対応 | 対応 | 対応 | 対応 |

### 2.2 VoiceReach適合性スコア

| 評価軸 (重み) | Claude Haiku 4.5 | GPT-4o mini | GPT-4.1 nano | Gemini 2.5 Flash | Gemini 3 Flash |
|---|---|---|---|---|---|
| コスト効率 (25%) | B | A | A+ | A | B+ |
| レイテンシ (25%) | B | B+ | B+ | A+ | A |
| 日本語品質 (20%) | A | B+ | B | A- | A |
| 指示追従 (15%) | A+ | A | A | A | A+ |
| 安定性/SLA (15%) | A | A | A | A- | B+ |
| **総合** | **B+** | **B+** | **B+** | **A** | **A-** |

---

## 3. 詳細分析

### 3.1 レイテンシ分析

VoiceReachでは以下のレイテンシ構成を考慮する必要がある:

```
総レイテンシ = ネットワーク往復 + TTFT + トークン生成時間

  ネットワーク往復: 日本国内サーバー想定で30-80ms
  TTFT: モデル依存（プロンプト処理時間）
  トークン生成: 出力トークン数 / 出力速度
```

#### 3.1.1 VoiceReach想定での推定レイテンシ

入力: ~3500トークン、出力: ~150トークン（4候補 + タグ）

| モデル | ネットワーク | TTFT | 生成時間 | 総レイテンシ | 2秒以内 |
|---|---|---|---|---|---|
| Claude Haiku 4.5 | ~50ms | ~490ms | ~1.4s | **~1.9s** | ギリギリ |
| Claude Sonnet 4.5 | ~50ms | ~900ms | ~1.9s | **~2.9s** | 超過 |
| GPT-4o mini | ~50ms | ~350ms | ~1.5s | **~1.9s** | ギリギリ |
| GPT-4.1 nano | ~50ms | ~370ms | ~1.5s | **~1.9s** | ギリギリ |
| **Gemini 2.5 Flash** | **~50ms** | **~280ms** | **~0.5s** | **~0.8s** | **余裕** |
| **Gemini 3 Flash** | **~50ms** | **~300ms** | **~0.7s** | **~1.0s** | **余裕** |

#### 3.1.2 ストリーミング利用時の体感レイテンシ

ストリーミングを使用する場合、最初の候補が生成された時点でUIに表示を開始できる:

| モデル | 最初の候補表示まで | 全4候補完了まで |
|---|---|---|
| Claude Haiku 4.5 | ~0.7s (TTFT + 30tok) | ~1.9s |
| GPT-4o mini | ~0.6s | ~1.9s |
| **Gemini 2.5 Flash** | **~0.4s** | **~0.8s** |
| **Gemini 3 Flash** | **~0.5s** | **~1.0s** |

### 3.2 コスト分析

#### 3.2.1 VoiceReachの1日あたりの使用パターン

VoiceReachの設計ドキュメントに基づく想定:

```
使用パターン:
  - 1日の活動時間: 12-16時間
  - トリガーイベント: 50-100回/日（Stage 2呼び出し回数）
  - 各呼び出し:
      入力: ~3500トークン（PVP 2000 + コンテキスト 500 + 指示 300 + 履歴 500 + フィードバック 200）
      出力: ~150トークン（4候補 + タグ）
  - 2巡目以降の追加呼び出し: 約30%のケースで発生
  - プロンプトキャッシュヒット率: ~80%（PVPは固定、コンテキストは変動）
```

#### 3.2.2 1日あたりのコスト推定（キャッシュなし）

75回/日の呼び出しを想定:

| モデル | 入力コスト/日 | 出力コスト/日 | **合計/日** | **合計/月 (30日)** |
|---|---|---|---|---|
| Claude Haiku 4.5 | $0.26 | $0.056 | **$0.32** | **$9.5** |
| Claude Sonnet 4.5 | $0.79 | $0.17 | **$0.96** | **$28.7** |
| GPT-4o mini | $0.039 | $0.0068 | **$0.046** | **$1.4** |
| GPT-4.1 nano | $0.026 | $0.0045 | **$0.031** | **$0.9** |
| **Gemini 2.5 Flash** | **$0.079** | **$0.028** | **$0.11** | **$3.2** |
| Gemini 3 Flash | $0.13 | $0.034 | **$0.16** | **$4.9** |

計算式:
```
入力トークン/日 = 3500 tok * 75 calls = 262,500 tok
出力トークン/日 = 150 tok * 75 calls = 11,250 tok
```

#### 3.2.3 プロンプトキャッシュ適用後のコスト

AnthropicとGoogleは両方ともプロンプトキャッシュを提供。PVP（~2000トークン）は変更頻度が低くキャッシュ効率が高い。

**Anthropicのプロンプトキャッシュ**:
- キャッシュ書き込み: 基本料金の1.25倍
- キャッシュ読み込み: 基本料金の**0.1倍**（90%割引）
- キャッシュTTL: 5分（使用するたびにリセット）

**Googleのコンテキストキャッシュ**:
- キャッシュ読み込み: 基本入力料金の0.1倍
- キャッシュストレージ: $1-4.50/M tok/時間

#### 3.2.4 キャッシュ適用後の月額コスト推定

PVP 2000トークンのキャッシュヒット率80%を想定:

| モデル | キャッシュなし/月 | キャッシュあり/月 | 節約率 |
|---|---|---|---|
| Claude Haiku 4.5 | $9.5 | **~$5.2** | 45% |
| Gemini 2.5 Flash | $3.2 | **~$2.0** | 38% |
| GPT-4.1 nano | $0.9 | **~$0.6** | 33% |

**重要な発見**: いずれのモデルも月額コストは非常に低い。コスト面ではGPT-4.1 nanoが最安だが、品質とのトレードオフを考慮する必要がある。

### 3.3 日本語品質の詳細評価

#### 3.3.1 評価観点

VoiceReachのAAC用途では、以下の日本語品質が重要:

1. **口語的自然さ**: 「おかゆがいいな」「すごいじゃん」のような自然な口語体
2. **PVP模倣精度**: 個人固有の表現パターン（「ぼちぼち」「だよなぁ」等）の再現
3. **敬語/カジュアルの使い分け**: 相手（家族/介護者/医師）に応じた語調変化
4. **短文の質**: 5-30文字程度の短い候補の自然さ
5. **意図の多様性**: 意図軸分散指示に従った「意味的に遠い」候補の生成

#### 3.3.2 モデル別評価

| 評価項目 | Claude Haiku 4.5 | Claude Sonnet 4.5 | GPT-4o mini | GPT-4.1 nano | Gemini 2.5 Flash |
|---|---|---|---|---|---|
| 口語的自然さ | A | A+ | B+ | B | A- |
| PVP模倣精度 | A | A+ | B+ | B- | A- |
| 敬語使い分け | A | A+ | A- | B+ | A |
| 短文の質 | A | A+ | B+ | B | A- |
| 意図の多様性 | A+ | A+ | A | A- | A |

**分析**:
- **Claude系列**: 日本語の自然さとPVP模倣精度が最も高い。特にSonnet 4.5はペルソナ指示の忠実な遂行に優れる
- **GPT-4o mini / GPT-4.1 nano**: コスト効率は高いが、日本語の口語表現の自然さでは若干劣る。特にnanoモデルは短文での不自然さが目立つ場合がある
- **Gemini 2.5 Flash**: 日本語品質は良好で、特に速度との両立が優れている。多言語サポートが充実しており、日本語の理解・生成能力は高い

### 3.4 意図軸分散への対応力

VoiceReachの核心機能である「意図軸分散」（7つの意図軸から4つの異なる軸の候補を生成）への対応力を評価:

| 能力 | Claude Haiku 4.5 | GPT-4o mini | GPT-4.1 nano | Gemini 2.5 Flash |
|---|---|---|---|---|
| 7軸の概念理解 | 優秀 | 良好 | 良好 | 優秀 |
| 4候補の意図分散 | 安定 | 概ね安定 | やや不安定 | 安定 |
| タグ付き構造化出力 | 安定 | 安定 | 安定 | 安定 |
| 2巡目のフィードバック活用 | 優秀 | 良好 | 良好 | 優秀 |
| 低確率軸の包含 | 優秀 | 良好 | やや弱い | 良好 |
| 抽象度/温度の制御 | 優秀 | 良好 | 中程度 | 良好 |

---

## 4. API機能比較

### 4.1 ストリーミング出力

| 機能 | Anthropic (Claude) | OpenAI (GPT) | Google (Gemini) |
|---|---|---|---|
| SSEストリーミング | 対応 | 対応 | 対応 |
| 部分出力イベント | `content_block_delta` | `choices[0].delta` | `candidates[0].content` |
| ストリーム中断 | 対応 | 対応 | 対応 |
| 並列ストリーム | 複数リクエスト可 | 複数リクエスト可 | 複数リクエスト可 |

全プロバイダーがストリーミングに対応しており、VoiceReachのプログレッシブ表示パターンに適用可能。

### 4.2 システムプロンプト / プロンプトキャッシュ

| 機能 | Anthropic | OpenAI | Google |
|---|---|---|---|
| System prompt | 専用フィールド | `role: system` | `system_instruction` |
| プロンプトキャッシュ | `cache_control` 明示指定 | 自動キャッシュ | Context Caching API |
| キャッシュ割引 | 読み込み90%OFF | 50%OFF | 読み込み90%OFF |
| キャッシュTTL | 5分（自動延長）、1時間オプション | 自動管理 | 明示設定 |
| バッチAPI | 50%OFF | 50%OFF | 50%OFF |

### 4.3 レート制限

| プロバイダー | Tier 1 RPM | Tier 1 TPM | 備考 |
|---|---|---|---|
| Anthropic (Haiku 4.5) | 1,000 | 100K | 利用実績で自動昇格 |
| OpenAI (GPT-4o mini) | 500 | 200K | 課金額で昇格 |
| Google (Gemini 2.5 Flash) | 2,000 | 4M | 無料枠あり（15 RPM） |

VoiceReachの想定使用量（75回/日 = ~5 RPM平均）では、いずれのプロバイダーもレート制限に達しない。

### 4.4 Function Calling / Tool Use

| 機能 | Anthropic | OpenAI | Google |
|---|---|---|---|
| Function Calling | Tool Use API | Function Calling | Function Calling |
| 並列ツール呼び出し | 対応 | 対応 | 対応 |
| 構造化出力強制 | 対応（tool result） | JSON mode / Structured Outputs | JSON mode |

VoiceReachでは候補生成に構造化出力を利用するため、JSON modeまたはStructured Outputsが有用。

---

## 5. プロバイダー選定

### 5.1 推奨構成

#### プライマリ: Gemini 2.5 Flash

| 項目 | 詳細 |
|---|---|
| 用途 | Stage 2の日常的な候補生成（全呼び出しの80-90%） |
| 理由 | レイテンシが最速（TTFT 0.28s, 285 tok/s）でコスト効率も高い |
| 月額コスト | ~$2.0-3.2（キャッシュ利用時） |
| 日本語品質 | AAC用途では十分な品質（A-） |
| レイテンシ | 総レイテンシ~0.8s（2秒目標を大幅にクリア） |

**選定理由の詳細**:
1. 出力速度285 tok/sはClaude Haiku 4.5の2.5倍。150トークンの出力が約0.5秒で完了
2. TTFTが0.28秒で最速。ストリーミング利用時は最初の候補がわずか0.4秒で表示開始
3. 入力$0.30/出力$2.50の価格帯はClaude Haiku 4.5の約1/3
4. 1Mトークンのコンテキスト長があり、将来的な拡張にも余裕
5. Context Caching APIによりPVPのキャッシュコストを最小化

#### セカンダリ: Claude Haiku 4.5

| 項目 | 詳細 |
|---|---|
| 用途 | 高品質が必要な場面のフォールバック（全呼び出しの10-20%） |
| 理由 | 日本語品質と指示追従能力が最も高い |
| 月額コスト | ~$1.0-1.9（全呼び出しの15%として） |
| 日本語品質 | AAC用途で最高品質（A） |
| レイテンシ | 総レイテンシ~1.9s（2秒目標ギリギリ） |

**セカンダリとして使用する場面**:
1. 2巡目以降の候補再生成（フィードバック活用の精度が重要）
2. 新しい会話相手との初回対話（PVP活用の精度が重要）
3. 医療・緊急関連の候補生成（正確性が重要）
4. Gemini APIがダウンした場合のフォールバック

#### ターシャリ（緊急フォールバック）: GPT-4.1 nano

| 項目 | 詳細 |
|---|---|
| 用途 | 上記2つが利用不可の場合の最終フォールバック |
| 月額コスト | ~$0.1-0.2（緊急時のみ） |
| 日本語品質 | 最低限許容可能（B） |

### 5.2 プロバイダー切り替えロジック

```
候補生成リクエスト発生
  ↓
Gemini 2.5 Flash に送信（プライマリ）
  ├→ 成功: 候補をUIに反映
  ├→ 失敗 (429/503/timeout):
  │    ↓
  │    Claude Haiku 4.5 に送信（セカンダリ）
  │    ├→ 成功: 候補をUIに反映
  │    └→ 失敗:
  │         ↓
  │         GPT-4.1 nano に送信（ターシャリ）
  │         ├→ 成功: 候補をUIに反映
  │         └→ 失敗: ローカルLLMの候補をそのまま使用
  │
  └→ レイテンシ超過 (>2秒):
       → ローカルLLMの候補をそのまま使用（クラウド結果は破棄）
```

### 5.3 品質ベースの使い分け

```
コンテキストに応じた使い分け:

高品質モード（Claude Haiku 4.5）:
  - 医療関連の会話（薬、症状、処置）
  - 初対面の訪問者との会話
  - 感情的に重要な場面（家族との深い会話）
  - 2巡目以降の候補再生成

標準モード（Gemini 2.5 Flash）:
  - 日常的な挨拶・返答
  - 介護者への定型的な要望
  - 食事・環境の選択
  - リスニングモードの返答候補
```

---

## 6. ネットワーク障害時の設計

### 6.1 オフライン検出とモード切替

```
ネットワーク状態監視:
  - APIエンドポイントへのヘルスチェック（30秒間隔）
  - 直近3回のリクエストのレイテンシ監視
  - 接続断検出時は即座にオフラインモードへ遷移

オフラインモード:
  - Stage 2を無効化
  - Stage 1（ローカルLLM）の候補をそのまま最終候補として使用
  - オフラインモード専用のプロンプト最適化を適用
  - ネットワーク復帰を検出したらオンラインモードに自動復帰
```

### 6.2 低品質ネットワーク時の対応

```
レイテンシが高い場合（1-3秒）:
  - ストリーミングを活用し、部分的な候補から表示開始
  - ローカルLLM候補を表示しつつ、クラウド結果を裏で待機

レイテンシが非常に高い場合（3秒以上）:
  - クラウドリクエストを2秒でタイムアウト
  - ローカルLLM候補を使用
  - バックグラウンドでクラウド結果を受信し、次回リクエストのKVキャッシュに活用
```

---

## 7. 将来展望と代替候補

### 7.1 注目すべきモデルリリース

| モデル | 予想時期 | 注目点 |
|---|---|---|
| Gemini 3 Flash (GA) | 2026 Q1-Q2 | Preview版から正式版へ。さらなるコスト削減の可能性 |
| Claude 5 Haiku | 2026 (未定) | さらなる品質向上とレイテンシ改善が期待 |
| GPT-5 nano | 2026 (未定) | 極小モデルでの品質向上 |
| DeepSeek V4 | 2026 (未定) | コスト効率の高い代替候補 |

### 7.2 OpenRouterの活用

複数プロバイダーへの統一APIアクセスとして[OpenRouter](https://openrouter.ai/)の利用も検討に値する:

- 単一APIで複数プロバイダーに接続
- 自動フォールバック機能
- 価格比較が容易
- ただし追加のレイテンシ（プロキシ経由）が発生するため、VoiceReachの2秒目標との兼ね合いを検証する必要がある

---

## 8. コスト最適化戦略

### 8.1 プロンプトキャッシュの最大活用

```yaml
キャッシュ戦略:
  layer_1_static:  # ほぼ変化しない（日/週単位で更新）
    content: "PVP + 基本指示"
    size: ~2300 tokens
    cache_target: true  # 常にキャッシュ

  layer_2_session:  # セッション中変化しにくい（時間単位）
    content: "現在の環境状態 + 対話相手情報"
    size: ~300 tokens
    cache_target: true  # セッション中キャッシュ

  layer_3_dynamic:  # 毎回変化する
    content: "直近の会話履歴 + フィードバック + 最新コンテキスト"
    size: ~900 tokens
    cache_target: false  # キャッシュしない
```

### 8.2 バッチAPIの活用

先読みプリフェッチ（各候補が選ばれなかった場合の2巡目候補）はリアルタイム性が低いため、バッチAPIの利用で50%のコスト削減が可能:

```
先読みプリフェッチ:
  - 現在表示中の4候補それぞれに対する2巡目候補をバッチ生成
  - バッチAPIで50%割引適用
  - 結果はローカルにキャッシュし、必要時に即座に表示
```

### 8.3 月額コストの現実的な見通し

| シナリオ | 月額コスト | 備考 |
|---|---|---|
| 基本使用（50回/日） | **$1.5-2.0** | Gemini 2.5 Flash + キャッシュ |
| 標準使用（75回/日） | **$2.5-4.0** | Gemini主体 + Claude時々 |
| 高頻度使用（100回/日） | **$3.5-6.0** | Gemini主体 + Claude 20% |
| 先読み込み（+バッチ） | **+$1.0-2.0** | バッチAPI 50%割引適用 |

**結論**: 月額$5-8程度で高品質なAAC候補生成が実現可能。ALS支援機器の月額コストとして非常に合理的。

---

## 9. 実装上の注意点

### 9.1 APIクライアント設計

```
推奨アーキテクチャ:
  1. 統一インターフェース層
     - プロバイダー非依存のリクエスト/レスポンス形式を定義
     - プロバイダー切り替えをアプリケーション層から隠蔽

  2. プロバイダーアダプター層
     - Anthropic SDK / Google AI SDK / OpenAI SDK のラッパー
     - 各プロバイダーのレスポンス形式を統一形式に変換

  3. レジリエンス層
     - タイムアウト管理（2秒上限）
     - リトライ/フォールバック制御
     - サーキットブレーカーパターン
     - レイテンシ監視・ログ記録
```

### 9.2 セキュリティ考慮事項

```
送信データの最小化:
  - PVPはプロンプトキャッシュで保持（毎回送信しない）
  - 患者の実名は送信しない（PVP内でも匿名化）
  - 生体データ（視線、感情スコア）はテキスト化した要約のみ送信
  - 会話履歴は直近10ターンに制限

プロバイダー選定の考慮:
  - Anthropicはデータの学習利用をデフォルトでオプトアウト
  - Google Cloud / Vertex AIは企業向けのデータ保護保証あり
  - OpenAIはAPI経由のデータを学習に使用しない明示的なポリシー
```

---

## 10. リスクと対策

| リスク | 影響 | 対策 |
|---|---|---|
| API停止/障害 | 高品質候補が生成できない | 三段階フォールバック + ローカルLLM |
| 料金体系の変更 | 月額コスト増 | 複数プロバイダー対応で切り替え可能に |
| レイテンシスパイク | 2秒以内に間に合わない | タイムアウト + ローカルLLM候補で代替 |
| 日本語品質の低下 | AAC候補が不自然 | プロバイダー切り替え + プロンプト最適化 |
| プライバシー懸念 | 患者データの漏洩 | データ最小化 + エンドツーエンド暗号化 |
| API仕様変更 | 統合が壊れる | アダプター層による疎結合設計 |

---

## 11. 参考資料

- [Anthropic Claude API Pricing](https://platform.claude.com/docs/en/about-claude/pricing)
- [Anthropic Prompt Caching Documentation](https://platform.claude.com/docs/en/build-with-claude/prompt-caching)
- [Claude Reducing Latency Guide](https://platform.claude.com/docs/en/test-and-evaluate/strengthen-guardrails/reduce-latency)
- [Claude Haiku 4.5 Performance Analysis](https://artificialanalysis.ai/models/claude-4-5-haiku)
- [OpenAI API Pricing](https://openai.com/api/pricing/)
- [GPT-4.1 nano Performance Analysis](https://artificialanalysis.ai/models/gpt-4-1-nano)
- [Google Gemini Developer API Pricing](https://ai.google.dev/gemini-api/docs/pricing)
- [Gemini 2.5 Flash Performance Analysis](https://artificialanalysis.ai/models/gemini-2-5-flash/providers)
- [Gemini 3 Flash Introduction](https://blog.google/products/gemini/gemini-3-flash/)
- [AI API Pricing Comparison 2026](https://intuitionlabs.ai/articles/ai-api-pricing-comparison-grok-gemini-openai-claude)
- [LLM API Pricing Comparison 2025](https://intuitionlabs.ai/articles/llm-api-pricing-comparison-2025)
- [Claude vs Gemini Comparison 2025](https://www.glbgpt.com/resource/claude-vs-gemini-in-2025-a-hands-on-buyers-guide)
- [LLM Leaderboard 2025 (Vellum)](https://www.vellum.ai/llm-leaderboard)
- [Choosing LLMs for AI Agents](https://softcery.com/lab/ai-agent-llm-selection)
- [Gemini 3 Developer Guide](https://ai.google.dev/gemini-api/docs/gemini-3)
